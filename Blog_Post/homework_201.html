
<!DOCTYPE html>


<html lang="en" data-content_root="../" >

  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" /><meta name="viewport" content="width=device-width, initial-scale=1" />

    <title>Adam Unchained: Breaking Free from Default Parameters &#8212; My JupyterBook</title>
  
  
  
  <script data-cfasync="false">
    document.documentElement.dataset.mode = localStorage.getItem("mode") || "";
    document.documentElement.dataset.theme = localStorage.getItem("theme") || "";
  </script>
  
  <!-- Loaded before other Sphinx assets -->
  <link href="../_static/styles/theme.css?digest=dfe6caa3a7d634c4db9b" rel="stylesheet" />
<link href="../_static/styles/bootstrap.css?digest=dfe6caa3a7d634c4db9b" rel="stylesheet" />
<link href="../_static/styles/pydata-sphinx-theme.css?digest=dfe6caa3a7d634c4db9b" rel="stylesheet" />

  
  <link href="../_static/vendor/fontawesome/6.5.2/css/all.min.css?digest=dfe6caa3a7d634c4db9b" rel="stylesheet" />
  <link rel="preload" as="font" type="font/woff2" crossorigin href="../_static/vendor/fontawesome/6.5.2/webfonts/fa-solid-900.woff2" />
<link rel="preload" as="font" type="font/woff2" crossorigin href="../_static/vendor/fontawesome/6.5.2/webfonts/fa-brands-400.woff2" />
<link rel="preload" as="font" type="font/woff2" crossorigin href="../_static/vendor/fontawesome/6.5.2/webfonts/fa-regular-400.woff2" />

    <link rel="stylesheet" type="text/css" href="../_static/pygments.css?v=03e43079" />
    <link rel="stylesheet" type="text/css" href="../_static/styles/sphinx-book-theme.css?v=eba8b062" />
    <link rel="stylesheet" type="text/css" href="../_static/togglebutton.css?v=13237357" />
    <link rel="stylesheet" type="text/css" href="../_static/copybutton.css?v=76b2166b" />
    <link rel="stylesheet" type="text/css" href="../_static/mystnb.8ecb98da25f57f5357bf6f572d296f466b2cfe2517ffebfabe82451661e28f02.css?v=6644e6bb" />
    <link rel="stylesheet" type="text/css" href="../_static/sphinx-thebe.css?v=4fa983c6" />
    <link rel="stylesheet" type="text/css" href="../_static/sphinx-design.min.css?v=95c83b7e" />
  
  <!-- Pre-loaded scripts that we'll load fully later -->
  <link rel="preload" as="script" href="../_static/scripts/bootstrap.js?digest=dfe6caa3a7d634c4db9b" />
<link rel="preload" as="script" href="../_static/scripts/pydata-sphinx-theme.js?digest=dfe6caa3a7d634c4db9b" />
  <script src="../_static/vendor/fontawesome/6.5.2/js/all.min.js?digest=dfe6caa3a7d634c4db9b"></script>

    <script src="../_static/documentation_options.js?v=9eb32ce0"></script>
    <script src="../_static/doctools.js?v=9a2dae69"></script>
    <script src="../_static/sphinx_highlight.js?v=dc90522c"></script>
    <script src="../_static/clipboard.min.js?v=a7894cd8"></script>
    <script src="../_static/copybutton.js?v=f281be69"></script>
    <script src="../_static/scripts/sphinx-book-theme.js?v=887ef09a"></script>
    <script>let toggleHintShow = 'Click to show';</script>
    <script>let toggleHintHide = 'Click to hide';</script>
    <script>let toggleOpenOnPrint = 'true';</script>
    <script src="../_static/togglebutton.js?v=4a39c7ea"></script>
    <script>var togglebuttonSelector = '.toggle, .admonition.dropdown';</script>
    <script src="../_static/design-tabs.js?v=f930bc37"></script>
    <script>const THEBE_JS_URL = "https://unpkg.com/thebe@0.8.2/lib/index.js"; const thebe_selector = ".thebe,.cell"; const thebe_selector_input = "pre"; const thebe_selector_output = ".output, .cell_output"</script>
    <script async="async" src="../_static/sphinx-thebe.js?v=c100c467"></script>
    <script>var togglebuttonSelector = '.toggle, .admonition.dropdown';</script>
    <script>const THEBE_JS_URL = "https://unpkg.com/thebe@0.8.2/lib/index.js"; const thebe_selector = ".thebe,.cell"; const thebe_selector_input = "pre"; const thebe_selector_output = ".output, .cell_output"</script>
    <script>DOCUMENTATION_OPTIONS.pagename = 'Blog_Post/homework_201';</script>
    <link rel="canonical" href="/my-jupyter-book/Blog_Post/homework_201.html" />
    <link rel="index" title="Index" href="../genindex.html" />
    <link rel="search" title="Search" href="../search.html" />
    <link rel="prev" title="Applying Temporal Fusion Transformers for Air Quality Forecasting in Metro Manila" href="../group-activities/temporal.html" />
  <meta name="viewport" content="width=device-width, initial-scale=1"/>
  <meta name="docsearch:language" content="en"/>
  </head>
  
  
  <body data-bs-spy="scroll" data-bs-target=".bd-toc-nav" data-offset="180" data-bs-root-margin="0px 0px -60%" data-default-mode="">

  
  
  <div id="pst-skip-link" class="skip-link d-print-none"><a href="#main-content">Skip to main content</a></div>
  
  <div id="pst-scroll-pixel-helper"></div>
  
  <button type="button" class="btn rounded-pill" id="pst-back-to-top">
    <i class="fa-solid fa-arrow-up"></i>Back to top</button>

  
  <input type="checkbox"
          class="sidebar-toggle"
          id="pst-primary-sidebar-checkbox"/>
  <label class="overlay overlay-primary" for="pst-primary-sidebar-checkbox"></label>
  
  <input type="checkbox"
          class="sidebar-toggle"
          id="pst-secondary-sidebar-checkbox"/>
  <label class="overlay overlay-secondary" for="pst-secondary-sidebar-checkbox"></label>
  
  <div class="search-button__wrapper">
    <div class="search-button__overlay"></div>
    <div class="search-button__search-container">
<form class="bd-search d-flex align-items-center"
      action="../search.html"
      method="get">
  <i class="fa-solid fa-magnifying-glass"></i>
  <input type="search"
         class="form-control"
         name="q"
         id="search-input"
         placeholder="Search this book..."
         aria-label="Search this book..."
         autocomplete="off"
         autocorrect="off"
         autocapitalize="off"
         spellcheck="false"/>
  <span class="search-button__kbd-shortcut"><kbd class="kbd-shortcut__modifier">Ctrl</kbd>+<kbd>K</kbd></span>
</form></div>
  </div>

  <div class="pst-async-banner-revealer d-none">
  <aside id="bd-header-version-warning" class="d-none d-print-none" aria-label="Version warning"></aside>
</div>

  
    <header class="bd-header navbar navbar-expand-lg bd-navbar d-print-none">
    </header>
  

  <div class="bd-container">
    <div class="bd-container__inner bd-page-width">
      
      
      
      <div class="bd-sidebar-primary bd-sidebar">
        

  
  <div class="sidebar-header-items sidebar-primary__section">
    
    
    
    
  </div>
  
    <div class="sidebar-primary-items__start sidebar-primary__section">
        <div class="sidebar-primary-item">

  
    
  

<a class="navbar-brand logo" href="../intro.html">
  
  
  
  
  
    
    
      
    
    
    <img src="../_static/logo.png" class="logo__image only-light" alt="My JupyterBook - Home"/>
    <script>document.write(`<img src="../_static/logo.png" class="logo__image only-dark" alt="My JupyterBook - Home"/>`);</script>
  
  
</a></div>
        <div class="sidebar-primary-item">

 <script>
 document.write(`
   <button class="btn search-button-field search-button__button" title="Search" aria-label="Search" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <i class="fa-solid fa-magnifying-glass"></i>
    <span class="search-button__default-text">Search</span>
    <span class="search-button__kbd-shortcut"><kbd class="kbd-shortcut__modifier">Ctrl</kbd>+<kbd class="kbd-shortcut__modifier">K</kbd></span>
   </button>
 `);
 </script></div>
        <div class="sidebar-primary-item"><nav class="bd-links bd-docs-nav" aria-label="Main">
    <div class="bd-toc-item navbar-nav active">
        
        <ul class="nav bd-sidenav bd-sidenav__home-link">
            <li class="toctree-l1">
                <a class="reference internal" href="../intro.html">
                    The Portfolio of Dane Casiño
                </a>
            </li>
        </ul>
        <p aria-level="2" class="caption" role="heading"><span class="caption-text">Lectures</span></p>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="../lectures/lesson1/lesson1.html">Lecture 1 - Foundational Concept of Deep Learning</a></li>
<li class="toctree-l1"><a class="reference internal" href="../lectures/lesson2/lesson2.html">Lecture 2 - Understanding Deep Learning</a></li>
<li class="toctree-l1"><a class="reference internal" href="../lectures/lesson3/lesson3.html">Lecture 3 - PyTorch Tensor Objects Attributes and Methods</a></li>
<li class="toctree-l1"><a class="reference internal" href="../lectures/lesson4/lesson4.html">Lecture 4 - Main Types of Deep Learning Neural Networks</a></li>
<li class="toctree-l1"><a class="reference internal" href="../lectures/lesson5/lesson5.html">Lecture 5 - Applications of Deep Learning</a></li>
<li class="toctree-l1"><a class="reference internal" href="../lectures/lesson6/lesson6.html">Lecture 6 - Training CNN Model using MNIST Dataset</a></li>
</ul>
<p aria-level="2" class="caption" role="heading"><span class="caption-text">Exercises</span></p>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="../exercises/exercise-1-python-basics.html">Reaction Paper: “Machine Learning: Living in the Age of AI | A WIRED Film”</a></li>
</ul>
<p aria-level="2" class="caption" role="heading"><span class="caption-text">Labs</span></p>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="../labs/Laboratory%20Activty%201.html">Laboratory Activty 1</a></li>
<li class="toctree-l1"><a class="reference internal" href="../labs/Laboratory%20Activty%202.html">Laboratory Activty 2</a></li>
<li class="toctree-l1"><a class="reference internal" href="../labs/Laboratory%20Activity%203.html">Laboratory Activity 3</a></li>
<li class="toctree-l1"><a class="reference internal" href="../labs/Laboratory%20Activity%204.html">Laboratory Activity 4</a></li>
<li class="toctree-l1"><a class="reference internal" href="../labs/lab-5-pytorch-intro.html">Laboratory Task 5</a></li>
<li class="toctree-l1"><a class="reference internal" href="../labs/Laboratory_Activty.html">Laboratory Task 6</a></li>
<li class="toctree-l1"><a class="reference internal" href="../labs/Lab%20Activity%20201.html">Lab Activity 201: Exploring Hyperparameters (Activation Functions and Optimizers)</a></li>
</ul>
<p aria-level="2" class="caption" role="heading"><span class="caption-text">Group Projects</span></p>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="../group-activities/resources.html">Group Activities</a></li>
<li class="toctree-l1"><a class="reference internal" href="../group-activities/temporal.html">Applying Temporal Fusion Transformers for Air Quality Forecasting in Metro Manila</a></li>
</ul>
<p aria-level="2" class="caption" role="heading"><span class="caption-text">Deep Learning Blog Post</span></p>
<ul class="current nav bd-sidenav">
<li class="toctree-l1 current active"><a class="current reference internal" href="#">Adam Unchained: Breaking Free from Default Parameters</a></li>
</ul>

    </div>
</nav></div>
    </div>
  
  
  <div class="sidebar-primary-items__end sidebar-primary__section">
  </div>
  
  <div id="rtd-footer-container"></div>


      </div>
      
      <main id="main-content" class="bd-main" role="main">
        
        

<div class="sbt-scroll-pixel-helper"></div>

          <div class="bd-content">
            <div class="bd-article-container">
              
              <div class="bd-header-article d-print-none">
<div class="header-article-items header-article__inner">
  
    <div class="header-article-items__start">
      
        <div class="header-article-item"><button class="sidebar-toggle primary-toggle btn btn-sm" title="Toggle primary sidebar" data-bs-placement="bottom" data-bs-toggle="tooltip">
  <span class="fa-solid fa-bars"></span>
</button></div>
      
    </div>
  
  
    <div class="header-article-items__end">
      
        <div class="header-article-item">

<div class="article-header-buttons">





<div class="dropdown dropdown-source-buttons">
  <button class="btn dropdown-toggle" type="button" data-bs-toggle="dropdown" aria-expanded="false" aria-label="Source repositories">
    <i class="fab fa-github"></i>
  </button>
  <ul class="dropdown-menu">
      
      
      
      <li><a href="https://github.com/Danecash/my-jupyter-book" target="_blank"
   class="btn btn-sm btn-source-repository-button dropdown-item"
   title="Source repository"
   data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fab fa-github"></i>
  </span>
<span class="btn__text-container">Repository</span>
</a>
</li>
      
      
      
      
      <li><a href="https://github.com/Danecash/my-jupyter-book/issues/new?title=Issue%20on%20page%20%2FBlog_Post/homework_201.html&body=Your%20issue%20content%20here." target="_blank"
   class="btn btn-sm btn-source-issues-button dropdown-item"
   title="Open an issue"
   data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-lightbulb"></i>
  </span>
<span class="btn__text-container">Open issue</span>
</a>
</li>
      
  </ul>
</div>






<div class="dropdown dropdown-download-buttons">
  <button class="btn dropdown-toggle" type="button" data-bs-toggle="dropdown" aria-expanded="false" aria-label="Download this page">
    <i class="fas fa-download"></i>
  </button>
  <ul class="dropdown-menu">
      
      
      
      <li><a href="../_sources/Blog_Post/homework_201.ipynb" target="_blank"
   class="btn btn-sm btn-download-source-button dropdown-item"
   title="Download source file"
   data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-file"></i>
  </span>
<span class="btn__text-container">.ipynb</span>
</a>
</li>
      
      
      
      
      <li>
<button onclick="window.print()"
  class="btn btn-sm btn-download-pdf-button dropdown-item"
  title="Print to PDF"
  data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-file-pdf"></i>
  </span>
<span class="btn__text-container">.pdf</span>
</button>
</li>
      
  </ul>
</div>




<button onclick="toggleFullScreen()"
  class="btn btn-sm btn-fullscreen-button"
  title="Fullscreen mode"
  data-bs-placement="bottom" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-expand"></i>
  </span>

</button>



<script>
document.write(`
  <button class="btn btn-sm nav-link pst-navbar-icon theme-switch-button" title="light/dark" aria-label="light/dark" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <i class="theme-switch fa-solid fa-sun fa-lg" data-mode="light"></i>
    <i class="theme-switch fa-solid fa-moon fa-lg" data-mode="dark"></i>
    <i class="theme-switch fa-solid fa-circle-half-stroke fa-lg" data-mode="auto"></i>
  </button>
`);
</script>


<script>
document.write(`
  <button class="btn btn-sm pst-navbar-icon search-button search-button__button" title="Search" aria-label="Search" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <i class="fa-solid fa-magnifying-glass fa-lg"></i>
  </button>
`);
</script>
<button class="sidebar-toggle secondary-toggle btn btn-sm" title="Toggle secondary sidebar" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <span class="fa-solid fa-list"></span>
</button>
</div></div>
      
    </div>
  
</div>
</div>
              
              

<div id="jb-print-docs-body" class="onlyprint">
    <h1>Adam Unchained: Breaking Free from Default Parameters</h1>
    <!-- Table of contents -->
    <div id="print-main-content">
        <div id="jb-print-toc">
            
            <div>
                <h2> Contents </h2>
            </div>
            <nav aria-label="Page">
                <ul class="visible nav section-nav flex-column">
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#introduction">Introduction</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#why-this-matters">Why This Matters</a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#theoretical-foundation">Theoretical Foundation</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#what-is-adam">What is Adam?</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#the-adam-update-equations">The Adam Update Equations</a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#experimental-setup">Experimental Setup</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#methodology">Methodology</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#parameters-tested">Parameters Tested</a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#experiment-1-learning-rate-sensitivity">Experiment 1: Learning Rate Sensitivity</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#what-we-re-testing">What We’re Testing</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#hypothesis">Hypothesis</a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#results-analysis">Results Analysis</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#key-questions">Key Questions:</a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#key-insights-and-findings">Key Insights and Findings</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#practical-recommendations-for-practitioners">Practical Recommendations for Practitioners</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#understanding-adam-through-code">Understanding Adam Through Code</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#portfolio-impact">Portfolio Impact</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#conclusion-and-key-takeaways">Conclusion and Key Takeaways</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#references">References</a></li>
</ul>
            </nav>
        </div>
    </div>
</div>

              
                
<div id="searchbox"></div>
                <article class="bd-article">
                  
  <section class="tex2jax_ignore mathjax_ignore" id="adam-unchained-breaking-free-from-default-parameters">
<h1>Adam Unchained: Breaking Free from Default Parameters<a class="headerlink" href="#adam-unchained-breaking-free-from-default-parameters" title="Link to this heading">#</a></h1>
<section id="introduction">
<h2>Introduction<a class="headerlink" href="#introduction" title="Link to this heading">#</a></h2>
<p>We’ve all typed <code class="docutils literal notranslate"><span class="pre">optimizer='adam'</span></code> with default settings, trusting that the magic will happen. But what if I told you that peeking under Adam’s hood reveals opportunities for significant performance gains? In this deep dive, we’ll explore the Adam optimizer beyond its default parameters and discover why “it just works” isn’t always good enough.</p>
<p><strong>Myth Busting:</strong> Adam’s parameters DO need tuning for optimal performance, and the defaults are starting points, not finishing lines.</p>
<section id="why-this-matters">
<h3>Why This Matters<a class="headerlink" href="#why-this-matters" title="Link to this heading">#</a></h3>
<ul class="simple">
<li><p>Adam is the most popular optimizer in deep learning</p></li>
<li><p>Default parameters work well generally, but aren’t optimal for specific tasks</p></li>
<li><p>Understanding parameter effects helps debug training issues and improve performance</p></li>
</ul>
</section>
</section>
<section id="theoretical-foundation">
<h2>Theoretical Foundation<a class="headerlink" href="#theoretical-foundation" title="Link to this heading">#</a></h2>
<section id="what-is-adam">
<h3>What is Adam?<a class="headerlink" href="#what-is-adam" title="Link to this heading">#</a></h3>
<p>Adam (Adaptive Moment Estimation) combines the best of two worlds:</p>
<ul class="simple">
<li><p><strong>Momentum</strong> (like SGD with momentum) for navigating ravines</p></li>
<li><p><strong>Adaptive learning rates</strong> (like RMSProp) for handling sparse gradients</p></li>
</ul>
</section>
<section id="the-adam-update-equations">
<h3>The Adam Update Equations<a class="headerlink" href="#the-adam-update-equations" title="Link to this heading">#</a></h3>
<p>The algorithm maintains two moving averages:</p>
<ul class="simple">
<li><p><strong>First moment (m)</strong>: Exponential moving average of gradients</p></li>
<li><p><strong>Second moment (v)</strong>: Exponential moving average of squared gradients</p></li>
</ul>
<p>These are bias-corrected and used to compute parameter updates.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Import necessary libraries</span>
<span class="kn">import</span><span class="w"> </span><span class="nn">tensorflow</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">tf</span>
<span class="kn">import</span><span class="w"> </span><span class="nn">matplotlib.pyplot</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">plt</span>
<span class="kn">import</span><span class="w"> </span><span class="nn">numpy</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">np</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">tensorflow.keras</span><span class="w"> </span><span class="kn">import</span> <span class="n">layers</span><span class="p">,</span> <span class="n">models</span>
<span class="kn">import</span><span class="w"> </span><span class="nn">warnings</span>
<span class="n">warnings</span><span class="o">.</span><span class="n">filterwarnings</span><span class="p">(</span><span class="s1">&#39;ignore&#39;</span><span class="p">)</span>
<span class="kn">import</span><span class="w"> </span><span class="nn">pandas</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">pd</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">datetime</span><span class="w"> </span><span class="kn">import</span> <span class="n">datetime</span>
<span class="kn">import</span><span class="w"> </span><span class="nn">seaborn</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">sns</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">sklearn.metrics</span><span class="w"> </span><span class="kn">import</span> <span class="n">classification_report</span><span class="p">,</span> <span class="n">confusion_matrix</span>

<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Libraries imported successfully!&quot;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;TensorFlow version: </span><span class="si">{</span><span class="n">tf</span><span class="o">.</span><span class="n">__version__</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Libraries imported successfully!
TensorFlow version: 2.20.0
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Enhanced analysis and visualization functions</span>
<span class="k">def</span><span class="w"> </span><span class="nf">analyze_convergence_speed</span><span class="p">(</span><span class="n">histories</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Analyze how quickly each configuration converges&quot;&quot;&quot;</span>
    <span class="n">convergence_data</span> <span class="o">=</span> <span class="p">[]</span>
    
    <span class="k">for</span> <span class="n">config_name</span><span class="p">,</span> <span class="n">history</span> <span class="ow">in</span> <span class="n">histories</span><span class="o">.</span><span class="n">items</span><span class="p">():</span>
        <span class="c1"># Find epoch where validation loss stabilizes (within 1% of final loss)</span>
        <span class="n">val_loss</span> <span class="o">=</span> <span class="n">history</span><span class="o">.</span><span class="n">history</span><span class="p">[</span><span class="s1">&#39;val_loss&#39;</span><span class="p">]</span>
        <span class="n">final_loss</span> <span class="o">=</span> <span class="n">val_loss</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span>
        
        <span class="k">for</span> <span class="n">epoch</span><span class="p">,</span> <span class="n">loss</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">val_loss</span><span class="p">):</span>
            <span class="k">if</span> <span class="nb">abs</span><span class="p">(</span><span class="n">loss</span> <span class="o">-</span> <span class="n">final_loss</span><span class="p">)</span> <span class="o">/</span> <span class="n">final_loss</span> <span class="o">&lt;=</span> <span class="mf">0.01</span><span class="p">:</span>
                <span class="n">convergence_epoch</span> <span class="o">=</span> <span class="n">epoch</span>
                <span class="k">break</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">convergence_epoch</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">val_loss</span><span class="p">)</span> <span class="o">-</span> <span class="mi">1</span>
        
        <span class="n">convergence_data</span><span class="o">.</span><span class="n">append</span><span class="p">({</span>
            <span class="s1">&#39;config&#39;</span><span class="p">:</span> <span class="n">config_name</span><span class="p">,</span>
            <span class="s1">&#39;convergence_epoch&#39;</span><span class="p">:</span> <span class="n">convergence_epoch</span><span class="p">,</span>
            <span class="s1">&#39;final_accuracy&#39;</span><span class="p">:</span> <span class="n">history</span><span class="o">.</span><span class="n">history</span><span class="p">[</span><span class="s1">&#39;val_accuracy&#39;</span><span class="p">][</span><span class="o">-</span><span class="mi">1</span><span class="p">],</span>
            <span class="s1">&#39;final_loss&#39;</span><span class="p">:</span> <span class="n">final_loss</span><span class="p">,</span>
            <span class="s1">&#39;stability&#39;</span><span class="p">:</span> <span class="n">np</span><span class="o">.</span><span class="n">std</span><span class="p">(</span><span class="n">val_loss</span><span class="p">[</span><span class="o">-</span><span class="mi">5</span><span class="p">:])</span>  <span class="c1"># Last 5 epochs std</span>
        <span class="p">})</span>
    
    <span class="k">return</span> <span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">(</span><span class="n">convergence_data</span><span class="p">)</span>

<span class="k">def</span><span class="w"> </span><span class="nf">plot_parameter_sensitivity</span><span class="p">(</span><span class="n">histories_df</span><span class="p">,</span> <span class="n">param_name</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Create sensitivity analysis plots&quot;&quot;&quot;</span>
    <span class="n">fig</span><span class="p">,</span> <span class="n">axes</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">subplots</span><span class="p">(</span><span class="mi">2</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">15</span><span class="p">,</span> <span class="mi">10</span><span class="p">))</span>
    
    <span class="c1"># Extract parameter values</span>
    <span class="n">param_values</span> <span class="o">=</span> <span class="p">[]</span>
    <span class="n">final_accuracies</span> <span class="o">=</span> <span class="p">[]</span>
    <span class="n">convergence_speeds</span> <span class="o">=</span> <span class="p">[]</span>
    <span class="n">stabilities</span> <span class="o">=</span> <span class="p">[]</span>
    
    <span class="k">for</span> <span class="n">config</span> <span class="ow">in</span> <span class="n">histories_df</span><span class="p">[</span><span class="s1">&#39;config&#39;</span><span class="p">]:</span>
        <span class="k">if</span> <span class="n">param_name</span> <span class="ow">in</span> <span class="n">config</span><span class="p">:</span>
            <span class="c1"># Extract parameter value from config name</span>
            <span class="n">value</span> <span class="o">=</span> <span class="nb">float</span><span class="p">(</span><span class="n">config</span><span class="o">.</span><span class="n">split</span><span class="p">(</span><span class="s1">&#39;_&#39;</span><span class="p">)[</span><span class="o">-</span><span class="mi">1</span><span class="p">])</span>
            <span class="n">param_values</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">value</span><span class="p">)</span>
            
            <span class="n">config_data</span> <span class="o">=</span> <span class="n">histories_df</span><span class="p">[</span><span class="n">histories_df</span><span class="p">[</span><span class="s1">&#39;config&#39;</span><span class="p">]</span> <span class="o">==</span> <span class="n">config</span><span class="p">]</span><span class="o">.</span><span class="n">iloc</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
            <span class="n">final_accuracies</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">config_data</span><span class="p">[</span><span class="s1">&#39;final_accuracy&#39;</span><span class="p">])</span>
            <span class="n">convergence_speeds</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">config_data</span><span class="p">[</span><span class="s1">&#39;convergence_epoch&#39;</span><span class="p">])</span>
            <span class="n">stabilities</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">config_data</span><span class="p">[</span><span class="s1">&#39;stability&#39;</span><span class="p">])</span>
    
    <span class="c1"># Sort by parameter value</span>
    <span class="n">sorted_data</span> <span class="o">=</span> <span class="nb">sorted</span><span class="p">(</span><span class="nb">zip</span><span class="p">(</span><span class="n">param_values</span><span class="p">,</span> <span class="n">final_accuracies</span><span class="p">,</span> <span class="n">convergence_speeds</span><span class="p">,</span> <span class="n">stabilities</span><span class="p">))</span>
    <span class="n">param_values</span><span class="p">,</span> <span class="n">final_accuracies</span><span class="p">,</span> <span class="n">convergence_speeds</span><span class="p">,</span> <span class="n">stabilities</span> <span class="o">=</span> <span class="nb">zip</span><span class="p">(</span><span class="o">*</span><span class="n">sorted_data</span><span class="p">)</span>
    
    <span class="c1"># Plot 1: Final Accuracy vs Parameter</span>
    <span class="n">axes</span><span class="p">[</span><span class="mi">0</span><span class="p">,</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">param_values</span><span class="p">,</span> <span class="n">final_accuracies</span><span class="p">,</span> <span class="s1">&#39;o-&#39;</span><span class="p">,</span> <span class="n">linewidth</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span> <span class="n">markersize</span><span class="o">=</span><span class="mi">8</span><span class="p">)</span>
    <span class="n">axes</span><span class="p">[</span><span class="mi">0</span><span class="p">,</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">set_title</span><span class="p">(</span><span class="sa">f</span><span class="s1">&#39;</span><span class="si">{</span><span class="n">param_name</span><span class="si">}</span><span class="s1"> vs Final Accuracy&#39;</span><span class="p">)</span>
    <span class="n">axes</span><span class="p">[</span><span class="mi">0</span><span class="p">,</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">set_xlabel</span><span class="p">(</span><span class="n">param_name</span><span class="p">)</span>
    <span class="n">axes</span><span class="p">[</span><span class="mi">0</span><span class="p">,</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">set_ylabel</span><span class="p">(</span><span class="s1">&#39;Accuracy&#39;</span><span class="p">)</span>
    <span class="n">axes</span><span class="p">[</span><span class="mi">0</span><span class="p">,</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">grid</span><span class="p">(</span><span class="kc">True</span><span class="p">,</span> <span class="n">alpha</span><span class="o">=</span><span class="mf">0.3</span><span class="p">)</span>
    
    <span class="c1"># Plot 2: Convergence Speed vs Parameter</span>
    <span class="n">axes</span><span class="p">[</span><span class="mi">0</span><span class="p">,</span><span class="mi">1</span><span class="p">]</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">param_values</span><span class="p">,</span> <span class="n">convergence_speeds</span><span class="p">,</span> <span class="s1">&#39;s-&#39;</span><span class="p">,</span> <span class="n">linewidth</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span> <span class="n">markersize</span><span class="o">=</span><span class="mi">8</span><span class="p">,</span> <span class="n">color</span><span class="o">=</span><span class="s1">&#39;orange&#39;</span><span class="p">)</span>
    <span class="n">axes</span><span class="p">[</span><span class="mi">0</span><span class="p">,</span><span class="mi">1</span><span class="p">]</span><span class="o">.</span><span class="n">set_title</span><span class="p">(</span><span class="sa">f</span><span class="s1">&#39;</span><span class="si">{</span><span class="n">param_name</span><span class="si">}</span><span class="s1"> vs Convergence Speed&#39;</span><span class="p">)</span>
    <span class="n">axes</span><span class="p">[</span><span class="mi">0</span><span class="p">,</span><span class="mi">1</span><span class="p">]</span><span class="o">.</span><span class="n">set_xlabel</span><span class="p">(</span><span class="n">param_name</span><span class="p">)</span>
    <span class="n">axes</span><span class="p">[</span><span class="mi">0</span><span class="p">,</span><span class="mi">1</span><span class="p">]</span><span class="o">.</span><span class="n">set_ylabel</span><span class="p">(</span><span class="s1">&#39;Convergence Epoch&#39;</span><span class="p">)</span>
    <span class="n">axes</span><span class="p">[</span><span class="mi">0</span><span class="p">,</span><span class="mi">1</span><span class="p">]</span><span class="o">.</span><span class="n">grid</span><span class="p">(</span><span class="kc">True</span><span class="p">,</span> <span class="n">alpha</span><span class="o">=</span><span class="mf">0.3</span><span class="p">)</span>
    
    <span class="c1"># Plot 3: Stability vs Parameter</span>
    <span class="n">axes</span><span class="p">[</span><span class="mi">1</span><span class="p">,</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">param_values</span><span class="p">,</span> <span class="n">stabilities</span><span class="p">,</span> <span class="s1">&#39;^-&#39;</span><span class="p">,</span> <span class="n">linewidth</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span> <span class="n">markersize</span><span class="o">=</span><span class="mi">8</span><span class="p">,</span> <span class="n">color</span><span class="o">=</span><span class="s1">&#39;red&#39;</span><span class="p">)</span>
    <span class="n">axes</span><span class="p">[</span><span class="mi">1</span><span class="p">,</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">set_title</span><span class="p">(</span><span class="sa">f</span><span class="s1">&#39;</span><span class="si">{</span><span class="n">param_name</span><span class="si">}</span><span class="s1"> vs Training Stability&#39;</span><span class="p">)</span>
    <span class="n">axes</span><span class="p">[</span><span class="mi">1</span><span class="p">,</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">set_xlabel</span><span class="p">(</span><span class="n">param_name</span><span class="p">)</span>
    <span class="n">axes</span><span class="p">[</span><span class="mi">1</span><span class="p">,</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">set_ylabel</span><span class="p">(</span><span class="s1">&#39;Loss Std (Last 5 epochs)&#39;</span><span class="p">)</span>
    <span class="n">axes</span><span class="p">[</span><span class="mi">1</span><span class="p">,</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">grid</span><span class="p">(</span><span class="kc">True</span><span class="p">,</span> <span class="n">alpha</span><span class="o">=</span><span class="mf">0.3</span><span class="p">)</span>
    
    <span class="c1"># Plot 4: All metrics together</span>
    <span class="n">ax2</span> <span class="o">=</span> <span class="n">axes</span><span class="p">[</span><span class="mi">1</span><span class="p">,</span><span class="mi">1</span><span class="p">]</span><span class="o">.</span><span class="n">twinx</span><span class="p">()</span>
    <span class="n">axes</span><span class="p">[</span><span class="mi">1</span><span class="p">,</span><span class="mi">1</span><span class="p">]</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">param_values</span><span class="p">,</span> <span class="n">final_accuracies</span><span class="p">,</span> <span class="s1">&#39;o-&#39;</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="s1">&#39;Accuracy&#39;</span><span class="p">,</span> <span class="n">color</span><span class="o">=</span><span class="s1">&#39;blue&#39;</span><span class="p">)</span>
    <span class="n">axes</span><span class="p">[</span><span class="mi">1</span><span class="p">,</span><span class="mi">1</span><span class="p">]</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">param_values</span><span class="p">,</span> <span class="n">convergence_speeds</span><span class="p">,</span> <span class="s1">&#39;s-&#39;</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="s1">&#39;Convergence Speed&#39;</span><span class="p">,</span> <span class="n">color</span><span class="o">=</span><span class="s1">&#39;orange&#39;</span><span class="p">)</span>
    <span class="n">ax2</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">param_values</span><span class="p">,</span> <span class="n">stabilities</span><span class="p">,</span> <span class="s1">&#39;^-&#39;</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="s1">&#39;Stability&#39;</span><span class="p">,</span> <span class="n">color</span><span class="o">=</span><span class="s1">&#39;red&#39;</span><span class="p">)</span>
    
    <span class="n">axes</span><span class="p">[</span><span class="mi">1</span><span class="p">,</span><span class="mi">1</span><span class="p">]</span><span class="o">.</span><span class="n">set_xlabel</span><span class="p">(</span><span class="n">param_name</span><span class="p">)</span>
    <span class="n">axes</span><span class="p">[</span><span class="mi">1</span><span class="p">,</span><span class="mi">1</span><span class="p">]</span><span class="o">.</span><span class="n">set_ylabel</span><span class="p">(</span><span class="s1">&#39;Accuracy/Convergence&#39;</span><span class="p">)</span>
    <span class="n">ax2</span><span class="o">.</span><span class="n">set_ylabel</span><span class="p">(</span><span class="s1">&#39;Stability&#39;</span><span class="p">)</span>
    <span class="n">axes</span><span class="p">[</span><span class="mi">1</span><span class="p">,</span><span class="mi">1</span><span class="p">]</span><span class="o">.</span><span class="n">set_title</span><span class="p">(</span><span class="sa">f</span><span class="s1">&#39;</span><span class="si">{</span><span class="n">param_name</span><span class="si">}</span><span class="s1"> - Combined Metrics&#39;</span><span class="p">)</span>
    <span class="n">axes</span><span class="p">[</span><span class="mi">1</span><span class="p">,</span><span class="mi">1</span><span class="p">]</span><span class="o">.</span><span class="n">legend</span><span class="p">()</span>
    <span class="n">ax2</span><span class="o">.</span><span class="n">legend</span><span class="p">(</span><span class="n">loc</span><span class="o">=</span><span class="s1">&#39;upper right&#39;</span><span class="p">)</span>
    <span class="n">axes</span><span class="p">[</span><span class="mi">1</span><span class="p">,</span><span class="mi">1</span><span class="p">]</span><span class="o">.</span><span class="n">grid</span><span class="p">(</span><span class="kc">True</span><span class="p">,</span> <span class="n">alpha</span><span class="o">=</span><span class="mf">0.3</span><span class="p">)</span>
    
    <span class="n">plt</span><span class="o">.</span><span class="n">tight_layout</span><span class="p">()</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>

<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Enhanced analysis functions defined!&quot;</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Enhanced analysis functions defined!
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Create the CNN model for MNIST</span>
<span class="k">def</span><span class="w"> </span><span class="nf">create_model</span><span class="p">():</span>
    <span class="n">model</span> <span class="o">=</span> <span class="n">models</span><span class="o">.</span><span class="n">Sequential</span><span class="p">([</span>
        <span class="n">layers</span><span class="o">.</span><span class="n">Conv2D</span><span class="p">(</span><span class="mi">32</span><span class="p">,</span> <span class="p">(</span><span class="mi">3</span><span class="p">,</span> <span class="mi">3</span><span class="p">),</span> <span class="n">activation</span><span class="o">=</span><span class="s1">&#39;relu&#39;</span><span class="p">,</span> <span class="n">input_shape</span><span class="o">=</span><span class="p">(</span><span class="mi">28</span><span class="p">,</span> <span class="mi">28</span><span class="p">,</span> <span class="mi">1</span><span class="p">)),</span>
        <span class="n">layers</span><span class="o">.</span><span class="n">MaxPooling2D</span><span class="p">((</span><span class="mi">2</span><span class="p">,</span> <span class="mi">2</span><span class="p">)),</span>
        <span class="n">layers</span><span class="o">.</span><span class="n">Conv2D</span><span class="p">(</span><span class="mi">64</span><span class="p">,</span> <span class="p">(</span><span class="mi">3</span><span class="p">,</span> <span class="mi">3</span><span class="p">),</span> <span class="n">activation</span><span class="o">=</span><span class="s1">&#39;relu&#39;</span><span class="p">),</span>
        <span class="n">layers</span><span class="o">.</span><span class="n">MaxPooling2D</span><span class="p">((</span><span class="mi">2</span><span class="p">,</span> <span class="mi">2</span><span class="p">)),</span>
        <span class="n">layers</span><span class="o">.</span><span class="n">Flatten</span><span class="p">(),</span>
        <span class="n">layers</span><span class="o">.</span><span class="n">Dense</span><span class="p">(</span><span class="mi">64</span><span class="p">,</span> <span class="n">activation</span><span class="o">=</span><span class="s1">&#39;relu&#39;</span><span class="p">),</span>
        <span class="n">layers</span><span class="o">.</span><span class="n">Dense</span><span class="p">(</span><span class="mi">10</span><span class="p">,</span> <span class="n">activation</span><span class="o">=</span><span class="s1">&#39;softmax&#39;</span><span class="p">)</span>
    <span class="p">])</span>
    <span class="k">return</span> <span class="n">model</span>

<span class="c1"># Test the model creation</span>
<span class="n">test_model</span> <span class="o">=</span> <span class="n">create_model</span><span class="p">()</span>
<span class="n">test_model</span><span class="o">.</span><span class="n">summary</span><span class="p">()</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Model created successfully!&quot;</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_html"><pre style="white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace"><span style="font-weight: bold">Model: "sequential"</span>
</pre>
</div><div class="output text_html"><pre style="white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓
┃<span style="font-weight: bold"> Layer (type)                         </span>┃<span style="font-weight: bold"> Output Shape                </span>┃<span style="font-weight: bold">         Param # </span>┃
┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩
│ conv2d (<span style="color: #0087ff; text-decoration-color: #0087ff">Conv2D</span>)                      │ (<span style="color: #00d7ff; text-decoration-color: #00d7ff">None</span>, <span style="color: #00af00; text-decoration-color: #00af00">26</span>, <span style="color: #00af00; text-decoration-color: #00af00">26</span>, <span style="color: #00af00; text-decoration-color: #00af00">32</span>)          │             <span style="color: #00af00; text-decoration-color: #00af00">320</span> │
├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤
│ max_pooling2d (<span style="color: #0087ff; text-decoration-color: #0087ff">MaxPooling2D</span>)         │ (<span style="color: #00d7ff; text-decoration-color: #00d7ff">None</span>, <span style="color: #00af00; text-decoration-color: #00af00">13</span>, <span style="color: #00af00; text-decoration-color: #00af00">13</span>, <span style="color: #00af00; text-decoration-color: #00af00">32</span>)          │               <span style="color: #00af00; text-decoration-color: #00af00">0</span> │
├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤
│ conv2d_1 (<span style="color: #0087ff; text-decoration-color: #0087ff">Conv2D</span>)                    │ (<span style="color: #00d7ff; text-decoration-color: #00d7ff">None</span>, <span style="color: #00af00; text-decoration-color: #00af00">11</span>, <span style="color: #00af00; text-decoration-color: #00af00">11</span>, <span style="color: #00af00; text-decoration-color: #00af00">64</span>)          │          <span style="color: #00af00; text-decoration-color: #00af00">18,496</span> │
├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤
│ max_pooling2d_1 (<span style="color: #0087ff; text-decoration-color: #0087ff">MaxPooling2D</span>)       │ (<span style="color: #00d7ff; text-decoration-color: #00d7ff">None</span>, <span style="color: #00af00; text-decoration-color: #00af00">5</span>, <span style="color: #00af00; text-decoration-color: #00af00">5</span>, <span style="color: #00af00; text-decoration-color: #00af00">64</span>)            │               <span style="color: #00af00; text-decoration-color: #00af00">0</span> │
├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤
│ flatten (<span style="color: #0087ff; text-decoration-color: #0087ff">Flatten</span>)                    │ (<span style="color: #00d7ff; text-decoration-color: #00d7ff">None</span>, <span style="color: #00af00; text-decoration-color: #00af00">1600</span>)                │               <span style="color: #00af00; text-decoration-color: #00af00">0</span> │
├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤
│ dense (<span style="color: #0087ff; text-decoration-color: #0087ff">Dense</span>)                        │ (<span style="color: #00d7ff; text-decoration-color: #00d7ff">None</span>, <span style="color: #00af00; text-decoration-color: #00af00">64</span>)                  │         <span style="color: #00af00; text-decoration-color: #00af00">102,464</span> │
├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤
│ dense_1 (<span style="color: #0087ff; text-decoration-color: #0087ff">Dense</span>)                      │ (<span style="color: #00d7ff; text-decoration-color: #00d7ff">None</span>, <span style="color: #00af00; text-decoration-color: #00af00">10</span>)                  │             <span style="color: #00af00; text-decoration-color: #00af00">650</span> │
└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘
</pre>
</div><div class="output text_html"><pre style="white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace"><span style="font-weight: bold"> Total params: </span><span style="color: #00af00; text-decoration-color: #00af00">121,930</span> (476.29 KB)
</pre>
</div><div class="output text_html"><pre style="white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace"><span style="font-weight: bold"> Trainable params: </span><span style="color: #00af00; text-decoration-color: #00af00">121,930</span> (476.29 KB)
</pre>
</div><div class="output text_html"><pre style="white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace"><span style="font-weight: bold"> Non-trainable params: </span><span style="color: #00af00; text-decoration-color: #00af00">0</span> (0.00 B)
</pre>
</div><div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Model created successfully!
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Load and preprocess MNIST data</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Loading MNIST dataset...&quot;</span><span class="p">)</span>
<span class="p">(</span><span class="n">x_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">),</span> <span class="p">(</span><span class="n">x_test</span><span class="p">,</span> <span class="n">y_test</span><span class="p">)</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">keras</span><span class="o">.</span><span class="n">datasets</span><span class="o">.</span><span class="n">mnist</span><span class="o">.</span><span class="n">load_data</span><span class="p">()</span>

<span class="c1"># Preprocess the data</span>
<span class="n">x_train</span> <span class="o">=</span> <span class="n">x_train</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="mi">28</span><span class="p">,</span> <span class="mi">28</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="s1">&#39;float32&#39;</span><span class="p">)</span> <span class="o">/</span> <span class="mf">255.0</span>
<span class="n">x_test</span> <span class="o">=</span> <span class="n">x_test</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="mi">28</span><span class="p">,</span> <span class="mi">28</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="s1">&#39;float32&#39;</span><span class="p">)</span> <span class="o">/</span> <span class="mf">255.0</span>

<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Training data shape: </span><span class="si">{</span><span class="n">x_train</span><span class="o">.</span><span class="n">shape</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Training labels shape: </span><span class="si">{</span><span class="n">y_train</span><span class="o">.</span><span class="n">shape</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Test data shape: </span><span class="si">{</span><span class="n">x_test</span><span class="o">.</span><span class="n">shape</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Test labels shape: </span><span class="si">{</span><span class="n">y_test</span><span class="o">.</span><span class="n">shape</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Data preprocessing completed!&quot;</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Loading MNIST dataset...
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Training data shape: (60000, 28, 28, 1)
Training labels shape: (60000,)
Test data shape: (10000, 28, 28, 1)
Test labels shape: (10000,)
Data preprocessing completed!
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Define the plotting function</span>
<span class="k">def</span><span class="w"> </span><span class="nf">plot_comparison</span><span class="p">(</span><span class="n">histories</span><span class="p">,</span> <span class="n">param_name</span><span class="p">,</span> <span class="n">values</span><span class="p">):</span>
    <span class="n">fig</span><span class="p">,</span> <span class="p">(</span><span class="n">ax1</span><span class="p">,</span> <span class="n">ax2</span><span class="p">)</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">subplots</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">15</span><span class="p">,</span> <span class="mi">5</span><span class="p">))</span>
    
    <span class="n">colors</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">cm</span><span class="o">.</span><span class="n">viridis</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">linspace</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="nb">len</span><span class="p">(</span><span class="n">values</span><span class="p">)))</span>
    
    <span class="k">for</span> <span class="n">i</span><span class="p">,</span> <span class="n">value</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">values</span><span class="p">):</span>
        <span class="n">key</span> <span class="o">=</span> <span class="sa">f</span><span class="s1">&#39;</span><span class="si">{</span><span class="n">param_name</span><span class="si">}</span><span class="s1">_</span><span class="si">{</span><span class="n">value</span><span class="si">}</span><span class="s1">&#39;</span>
        <span class="k">if</span> <span class="n">key</span> <span class="ow">in</span> <span class="n">histories</span><span class="p">:</span>  <span class="c1"># Safety check</span>
            <span class="n">history</span> <span class="o">=</span> <span class="n">histories</span><span class="p">[</span><span class="n">key</span><span class="p">]</span>
            
            <span class="c1"># Loss plot</span>
            <span class="n">ax1</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">history</span><span class="o">.</span><span class="n">history</span><span class="p">[</span><span class="s1">&#39;val_loss&#39;</span><span class="p">],</span> 
                    <span class="n">color</span><span class="o">=</span><span class="n">colors</span><span class="p">[</span><span class="n">i</span><span class="p">],</span> <span class="n">linewidth</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span>
                    <span class="n">label</span><span class="o">=</span><span class="sa">f</span><span class="s1">&#39;</span><span class="si">{</span><span class="n">param_name</span><span class="si">}</span><span class="s1">=</span><span class="si">{</span><span class="n">value</span><span class="si">}</span><span class="s1">&#39;</span><span class="p">)</span>
            
            <span class="c1"># Accuracy plot  </span>
            <span class="n">ax2</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">history</span><span class="o">.</span><span class="n">history</span><span class="p">[</span><span class="s1">&#39;val_accuracy&#39;</span><span class="p">],</span>
                    <span class="n">color</span><span class="o">=</span><span class="n">colors</span><span class="p">[</span><span class="n">i</span><span class="p">],</span> <span class="n">linewidth</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span>
                    <span class="n">label</span><span class="o">=</span><span class="sa">f</span><span class="s1">&#39;</span><span class="si">{</span><span class="n">param_name</span><span class="si">}</span><span class="s1">=</span><span class="si">{</span><span class="n">value</span><span class="si">}</span><span class="s1">&#39;</span><span class="p">)</span>
    
    <span class="n">ax1</span><span class="o">.</span><span class="n">set_title</span><span class="p">(</span><span class="sa">f</span><span class="s1">&#39;Validation Loss - </span><span class="si">{</span><span class="n">param_name</span><span class="si">}</span><span class="s1"> Comparison&#39;</span><span class="p">,</span> <span class="n">fontsize</span><span class="o">=</span><span class="mi">14</span><span class="p">,</span> <span class="n">fontweight</span><span class="o">=</span><span class="s1">&#39;bold&#39;</span><span class="p">)</span>
    <span class="n">ax2</span><span class="o">.</span><span class="n">set_title</span><span class="p">(</span><span class="sa">f</span><span class="s1">&#39;Validation Accuracy - </span><span class="si">{</span><span class="n">param_name</span><span class="si">}</span><span class="s1"> Comparison&#39;</span><span class="p">,</span> <span class="n">fontsize</span><span class="o">=</span><span class="mi">14</span><span class="p">,</span> <span class="n">fontweight</span><span class="o">=</span><span class="s1">&#39;bold&#39;</span><span class="p">)</span>
    <span class="n">ax1</span><span class="o">.</span><span class="n">set_xlabel</span><span class="p">(</span><span class="s1">&#39;Epoch&#39;</span><span class="p">)</span>
    <span class="n">ax2</span><span class="o">.</span><span class="n">set_xlabel</span><span class="p">(</span><span class="s1">&#39;Epoch&#39;</span><span class="p">)</span>
    <span class="n">ax1</span><span class="o">.</span><span class="n">set_ylabel</span><span class="p">(</span><span class="s1">&#39;Loss&#39;</span><span class="p">)</span>
    <span class="n">ax2</span><span class="o">.</span><span class="n">set_ylabel</span><span class="p">(</span><span class="s1">&#39;Accuracy&#39;</span><span class="p">)</span>
    <span class="n">ax1</span><span class="o">.</span><span class="n">legend</span><span class="p">(</span><span class="n">bbox_to_anchor</span><span class="o">=</span><span class="p">(</span><span class="mf">1.05</span><span class="p">,</span> <span class="mi">1</span><span class="p">),</span> <span class="n">loc</span><span class="o">=</span><span class="s1">&#39;upper left&#39;</span><span class="p">)</span>
    <span class="n">ax2</span><span class="o">.</span><span class="n">legend</span><span class="p">(</span><span class="n">bbox_to_anchor</span><span class="o">=</span><span class="p">(</span><span class="mf">1.05</span><span class="p">,</span> <span class="mi">1</span><span class="p">),</span> <span class="n">loc</span><span class="o">=</span><span class="s1">&#39;upper left&#39;</span><span class="p">)</span>
    <span class="n">ax1</span><span class="o">.</span><span class="n">grid</span><span class="p">(</span><span class="kc">True</span><span class="p">,</span> <span class="n">alpha</span><span class="o">=</span><span class="mf">0.3</span><span class="p">)</span>
    <span class="n">ax2</span><span class="o">.</span><span class="n">grid</span><span class="p">(</span><span class="kc">True</span><span class="p">,</span> <span class="n">alpha</span><span class="o">=</span><span class="mf">0.3</span><span class="p">)</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">tight_layout</span><span class="p">()</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>

<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Plotting function defined!&quot;</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Plotting function defined!
</pre></div>
</div>
</div>
</div>
</section>
</section>
<section id="experimental-setup">
<h2>Experimental Setup<a class="headerlink" href="#experimental-setup" title="Link to this heading">#</a></h2>
<section id="methodology">
<h3>Methodology<a class="headerlink" href="#methodology" title="Link to this heading">#</a></h3>
<ul class="simple">
<li><p><strong>Dataset</strong>: MNIST (60,000 training, 10,000 test images)</p></li>
<li><p><strong>Model</strong>: Simple CNN with 2 convolutional layers and 2 dense layers</p></li>
<li><p><strong>Training</strong>: 10 epochs for most experiments (5 for epsilon)</p></li>
<li><p><strong>Metrics</strong>: Validation accuracy, loss, convergence speed, stability</p></li>
</ul>
</section>
<section id="parameters-tested">
<h3>Parameters Tested<a class="headerlink" href="#parameters-tested" title="Link to this heading">#</a></h3>
<p>We systematically vary each Adam parameter while keeping others at defaults:</p>
<ul class="simple">
<li><p><strong>Learning Rate (α)</strong>: 1e-4, 1e-3, 1e-2, 1e-1</p></li>
<li><p><strong>Beta1 (β₁)</strong>: 0.5, 0.9, 0.99, 0.999</p></li>
<li><p><strong>Beta2 (β₂)</strong>: 0.9, 0.99, 0.999, 0.9999</p></li>
<li><p><strong>Epsilon (ε)</strong>: 1e-9, 1e-8, 1e-7, 1e-6, 1e-5</p></li>
</ul>
</section>
</section>
<section id="experiment-1-learning-rate-sensitivity">
<h2>Experiment 1: Learning Rate Sensitivity<a class="headerlink" href="#experiment-1-learning-rate-sensitivity" title="Link to this heading">#</a></h2>
<section id="what-we-re-testing">
<h3>What We’re Testing<a class="headerlink" href="#what-we-re-testing" title="Link to this heading">#</a></h3>
<p>Learning rate controls the step size in parameter updates. Too large causes oscillation; too small leads to slow convergence.</p>
</section>
<section id="hypothesis">
<h3>Hypothesis<a class="headerlink" href="#hypothesis" title="Link to this heading">#</a></h3>
<p>Moderate learning rates (0.001-0.01) should perform best, with extreme values showing instability or slow learning.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Experiment 1 - Learning Rate Sensitivity</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Starting Experiment 1: Learning Rate Sensitivity&quot;</span><span class="p">)</span>
<span class="n">learning_rates</span> <span class="o">=</span> <span class="p">[</span><span class="mf">1e-4</span><span class="p">,</span> <span class="mf">1e-3</span><span class="p">,</span> <span class="mf">1e-2</span><span class="p">,</span> <span class="mf">1e-1</span><span class="p">]</span>
<span class="n">histories</span> <span class="o">=</span> <span class="p">{}</span>

<span class="k">for</span> <span class="n">i</span><span class="p">,</span> <span class="n">lr</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">learning_rates</span><span class="p">):</span>
    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;  Training with learning rate: </span><span class="si">{</span><span class="n">lr</span><span class="si">}</span><span class="s2"> (</span><span class="si">{</span><span class="n">i</span><span class="o">+</span><span class="mi">1</span><span class="si">}</span><span class="s2">/</span><span class="si">{</span><span class="nb">len</span><span class="p">(</span><span class="n">learning_rates</span><span class="p">)</span><span class="si">}</span><span class="s2">)&quot;</span><span class="p">)</span>
    
    <span class="n">model</span> <span class="o">=</span> <span class="n">create_model</span><span class="p">()</span>
    <span class="n">optimizer</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">keras</span><span class="o">.</span><span class="n">optimizers</span><span class="o">.</span><span class="n">Adam</span><span class="p">(</span><span class="n">learning_rate</span><span class="o">=</span><span class="n">lr</span><span class="p">)</span>
    <span class="n">model</span><span class="o">.</span><span class="n">compile</span><span class="p">(</span><span class="n">optimizer</span><span class="o">=</span><span class="n">optimizer</span><span class="p">,</span>
                  <span class="n">loss</span><span class="o">=</span><span class="s1">&#39;sparse_categorical_crossentropy&#39;</span><span class="p">,</span>
                  <span class="n">metrics</span><span class="o">=</span><span class="p">[</span><span class="s1">&#39;accuracy&#39;</span><span class="p">])</span>
    
    <span class="n">history</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">x_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">,</span> 
                       <span class="n">epochs</span><span class="o">=</span><span class="mi">10</span><span class="p">,</span>  
                       <span class="n">validation_data</span><span class="o">=</span><span class="p">(</span><span class="n">x_test</span><span class="p">,</span> <span class="n">y_test</span><span class="p">),</span>
                       <span class="n">verbose</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
    <span class="n">histories</span><span class="p">[</span><span class="sa">f</span><span class="s1">&#39;lr_</span><span class="si">{</span><span class="n">lr</span><span class="si">}</span><span class="s1">&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">history</span>

<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Experiment 1 completed!&quot;</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Starting Experiment 1: Learning Rate Sensitivity
  Training with learning rate: 0.0001 (1/4)
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>  Training with learning rate: 0.001 (2/4)
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>  Training with learning rate: 0.01 (3/4)
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>  Training with learning rate: 0.1 (4/4)
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Experiment 1 completed!
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Experiment 2 - β1 (Momentum) Exploration</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Starting Experiment 2: β1 (Momentum) Exploration&quot;</span><span class="p">)</span>
<span class="n">beta1_values</span> <span class="o">=</span> <span class="p">[</span><span class="mf">0.5</span><span class="p">,</span> <span class="mf">0.9</span><span class="p">,</span> <span class="mf">0.99</span><span class="p">,</span> <span class="mf">0.999</span><span class="p">]</span>

<span class="k">for</span> <span class="n">i</span><span class="p">,</span> <span class="n">beta1</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">beta1_values</span><span class="p">):</span>
    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;  Training with beta1: </span><span class="si">{</span><span class="n">beta1</span><span class="si">}</span><span class="s2"> (</span><span class="si">{</span><span class="n">i</span><span class="o">+</span><span class="mi">1</span><span class="si">}</span><span class="s2">/</span><span class="si">{</span><span class="nb">len</span><span class="p">(</span><span class="n">beta1_values</span><span class="p">)</span><span class="si">}</span><span class="s2">)&quot;</span><span class="p">)</span>
    
    <span class="n">model</span> <span class="o">=</span> <span class="n">create_model</span><span class="p">()</span>
    <span class="n">optimizer</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">keras</span><span class="o">.</span><span class="n">optimizers</span><span class="o">.</span><span class="n">Adam</span><span class="p">(</span><span class="n">learning_rate</span><span class="o">=</span><span class="mf">1e-3</span><span class="p">,</span> <span class="n">beta_1</span><span class="o">=</span><span class="n">beta1</span><span class="p">)</span>
    <span class="n">model</span><span class="o">.</span><span class="n">compile</span><span class="p">(</span><span class="n">optimizer</span><span class="o">=</span><span class="n">optimizer</span><span class="p">,</span>
                  <span class="n">loss</span><span class="o">=</span><span class="s1">&#39;sparse_categorical_crossentropy&#39;</span><span class="p">,</span>
                  <span class="n">metrics</span><span class="o">=</span><span class="p">[</span><span class="s1">&#39;accuracy&#39;</span><span class="p">])</span>
    
    <span class="n">history</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">x_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">,</span> 
                       <span class="n">epochs</span><span class="o">=</span><span class="mi">10</span><span class="p">,</span>
                       <span class="n">validation_data</span><span class="o">=</span><span class="p">(</span><span class="n">x_test</span><span class="p">,</span> <span class="n">y_test</span><span class="p">),</span>
                       <span class="n">verbose</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
    <span class="n">histories</span><span class="p">[</span><span class="sa">f</span><span class="s1">&#39;beta1_</span><span class="si">{</span><span class="n">beta1</span><span class="si">}</span><span class="s1">&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">history</span>

<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Experiment 2 completed!&quot;</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Starting Experiment 2: β1 (Momentum) Exploration
  Training with beta1: 0.5 (1/4)
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>  Training with beta1: 0.9 (2/4)
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>  Training with beta1: 0.99 (3/4)
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>  Training with beta1: 0.999 (4/4)
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Experiment 2 completed!
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Experiment 3 - β2 (Squared Gradient Decay) Investigation</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Starting Experiment 3: β2 (Squared Gradient Decay) Investigation&quot;</span><span class="p">)</span>
<span class="n">beta2_values</span> <span class="o">=</span> <span class="p">[</span><span class="mf">0.9</span><span class="p">,</span> <span class="mf">0.99</span><span class="p">,</span> <span class="mf">0.999</span><span class="p">,</span> <span class="mf">0.9999</span><span class="p">]</span>

<span class="k">for</span> <span class="n">i</span><span class="p">,</span> <span class="n">beta2</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">beta2_values</span><span class="p">):</span>
    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;  Training with beta2: </span><span class="si">{</span><span class="n">beta2</span><span class="si">}</span><span class="s2"> (</span><span class="si">{</span><span class="n">i</span><span class="o">+</span><span class="mi">1</span><span class="si">}</span><span class="s2">/</span><span class="si">{</span><span class="nb">len</span><span class="p">(</span><span class="n">beta2_values</span><span class="p">)</span><span class="si">}</span><span class="s2">)&quot;</span><span class="p">)</span>
    
    <span class="n">model</span> <span class="o">=</span> <span class="n">create_model</span><span class="p">()</span>
    <span class="n">optimizer</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">keras</span><span class="o">.</span><span class="n">optimizers</span><span class="o">.</span><span class="n">Adam</span><span class="p">(</span><span class="n">learning_rate</span><span class="o">=</span><span class="mf">1e-3</span><span class="p">,</span> <span class="n">beta_2</span><span class="o">=</span><span class="n">beta2</span><span class="p">)</span>
    <span class="n">model</span><span class="o">.</span><span class="n">compile</span><span class="p">(</span><span class="n">optimizer</span><span class="o">=</span><span class="n">optimizer</span><span class="p">,</span>
                  <span class="n">loss</span><span class="o">=</span><span class="s1">&#39;sparse_categorical_crossentropy&#39;</span><span class="p">,</span>
                  <span class="n">metrics</span><span class="o">=</span><span class="p">[</span><span class="s1">&#39;accuracy&#39;</span><span class="p">])</span>
    
    <span class="n">history</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">x_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">,</span> 
                       <span class="n">epochs</span><span class="o">=</span><span class="mi">10</span><span class="p">,</span>
                       <span class="n">validation_data</span><span class="o">=</span><span class="p">(</span><span class="n">x_test</span><span class="p">,</span> <span class="n">y_test</span><span class="p">),</span>
                       <span class="n">verbose</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
    <span class="n">histories</span><span class="p">[</span><span class="sa">f</span><span class="s1">&#39;beta2_</span><span class="si">{</span><span class="n">beta2</span><span class="si">}</span><span class="s1">&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">history</span>

<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Experiment 3 completed!&quot;</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Starting Experiment 3: β2 (Squared Gradient Decay) Investigation
  Training with beta2: 0.9 (1/4)
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>  Training with beta2: 0.99 (2/4)
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>  Training with beta2: 0.999 (3/4)
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>  Training with beta2: 0.9999 (4/4)
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Experiment 3 completed!
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Experiment 4 - ε (Epsilon) Investigation</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Starting Experiment 4: ε (Epsilon) Investigation&quot;</span><span class="p">)</span>
<span class="n">epsilon_values</span> <span class="o">=</span> <span class="p">[</span><span class="mf">1e-9</span><span class="p">,</span> <span class="mf">1e-8</span><span class="p">,</span> <span class="mf">1e-7</span><span class="p">,</span> <span class="mf">1e-6</span><span class="p">,</span> <span class="mf">1e-5</span><span class="p">]</span>

<span class="k">for</span> <span class="n">i</span><span class="p">,</span> <span class="n">epsilon</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">epsilon_values</span><span class="p">):</span>
    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;  Training with epsilon: </span><span class="si">{</span><span class="n">epsilon</span><span class="si">}</span><span class="s2"> (</span><span class="si">{</span><span class="n">i</span><span class="o">+</span><span class="mi">1</span><span class="si">}</span><span class="s2">/</span><span class="si">{</span><span class="nb">len</span><span class="p">(</span><span class="n">epsilon_values</span><span class="p">)</span><span class="si">}</span><span class="s2">)&quot;</span><span class="p">)</span>
    
    <span class="n">model</span> <span class="o">=</span> <span class="n">create_model</span><span class="p">()</span>
    <span class="n">optimizer</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">keras</span><span class="o">.</span><span class="n">optimizers</span><span class="o">.</span><span class="n">Adam</span><span class="p">(</span><span class="n">learning_rate</span><span class="o">=</span><span class="mf">1e-3</span><span class="p">,</span> <span class="n">epsilon</span><span class="o">=</span><span class="n">epsilon</span><span class="p">)</span>
    <span class="n">model</span><span class="o">.</span><span class="n">compile</span><span class="p">(</span><span class="n">optimizer</span><span class="o">=</span><span class="n">optimizer</span><span class="p">,</span>
                  <span class="n">loss</span><span class="o">=</span><span class="s1">&#39;sparse_categorical_crossentropy&#39;</span><span class="p">,</span>
                  <span class="n">metrics</span><span class="o">=</span><span class="p">[</span><span class="s1">&#39;accuracy&#39;</span><span class="p">])</span>
    
    <span class="n">history</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">x_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">,</span> 
                       <span class="n">epochs</span><span class="o">=</span><span class="mi">5</span><span class="p">,</span>
                       <span class="n">validation_data</span><span class="o">=</span><span class="p">(</span><span class="n">x_test</span><span class="p">,</span> <span class="n">y_test</span><span class="p">),</span>
                       <span class="n">verbose</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
    <span class="n">histories</span><span class="p">[</span><span class="sa">f</span><span class="s1">&#39;epsilon_</span><span class="si">{</span><span class="n">epsilon</span><span class="si">}</span><span class="s1">&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">history</span>

<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Experiment 4 completed!&quot;</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Starting Experiment 4: ε (Epsilon) Investigation
  Training with epsilon: 1e-09 (1/5)
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>  Training with epsilon: 1e-08 (2/5)
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>  Training with epsilon: 1e-07 (3/5)
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>  Training with epsilon: 1e-06 (4/5)
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>  Training with epsilon: 1e-05 (5/5)
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Experiment 4 completed!
</pre></div>
</div>
</div>
</div>
</section>
</section>
<section id="results-analysis">
<h2>Results Analysis<a class="headerlink" href="#results-analysis" title="Link to this heading">#</a></h2>
<p>Now that we’ve run all experiments, let’s analyze the comprehensive results across all parameter variations.</p>
<section id="key-questions">
<h3>Key Questions:<a class="headerlink" href="#key-questions" title="Link to this heading">#</a></h3>
<ol class="arabic simple">
<li><p>Which parameters have the most impact on final accuracy?</p></li>
<li><p>How do parameters affect convergence speed?</p></li>
<li><p>What’s the stability trade-off for different settings?</p></li>
<li><p>Are the default parameters actually optimal?</p></li>
</ol>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Generate all comparison plots</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Generating comparison plots...&quot;</span><span class="p">)</span>

<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;</span><span class="se">\\</span><span class="s2">n1. Learning Rate Comparison:&quot;</span><span class="p">)</span>
<span class="n">plot_comparison</span><span class="p">(</span><span class="n">histories</span><span class="p">,</span> <span class="s1">&#39;lr&#39;</span><span class="p">,</span> <span class="n">learning_rates</span><span class="p">)</span>

<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;</span><span class="se">\\</span><span class="s2">n2. Beta1 Comparison:&quot;</span><span class="p">)</span>
<span class="n">plot_comparison</span><span class="p">(</span><span class="n">histories</span><span class="p">,</span> <span class="s1">&#39;beta1&#39;</span><span class="p">,</span> <span class="n">beta1_values</span><span class="p">)</span>

<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;</span><span class="se">\\</span><span class="s2">n3. Beta2 Comparison:&quot;</span><span class="p">)</span>
<span class="n">plot_comparison</span><span class="p">(</span><span class="n">histories</span><span class="p">,</span> <span class="s1">&#39;beta2&#39;</span><span class="p">,</span> <span class="n">beta2_values</span><span class="p">)</span>

<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;</span><span class="se">\\</span><span class="s2">n4. Epsilon Comparison:&quot;</span><span class="p">)</span>
<span class="n">plot_comparison</span><span class="p">(</span><span class="n">histories</span><span class="p">,</span> <span class="s1">&#39;epsilon&#39;</span><span class="p">,</span> <span class="n">epsilon_values</span><span class="p">)</span>

<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;All plots generated!&quot;</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Generating comparison plots...
\n1. Learning Rate Comparison:
</pre></div>
</div>
<img alt="../_images/dec0d09c79b207e7fd8abefe52fbed6b211e641b87a6dd4d89318553833bbc5f.png" src="../_images/dec0d09c79b207e7fd8abefe52fbed6b211e641b87a6dd4d89318553833bbc5f.png" />
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>\n2. Beta1 Comparison:
</pre></div>
</div>
<img alt="../_images/1b3c75bd4513d5c44dd372eb792144f2a6e695dc7968be6e5a641f51db83a0c5.png" src="../_images/1b3c75bd4513d5c44dd372eb792144f2a6e695dc7968be6e5a641f51db83a0c5.png" />
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>\n3. Beta2 Comparison:
</pre></div>
</div>
<img alt="../_images/6e658d335f961415f7468c47679bcca8404d2fdf3395a911925b859466f40353.png" src="../_images/6e658d335f961415f7468c47679bcca8404d2fdf3395a911925b859466f40353.png" />
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>\n4. Epsilon Comparison:
</pre></div>
</div>
<img alt="../_images/6af5a2681804c89a3a3010a7eda41150f82fb2519aaa9e5bd907094bb59de7d5.png" src="../_images/6af5a2681804c89a3a3010a7eda41150f82fb2519aaa9e5bd907094bb59de7d5.png" />
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>All plots generated!
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Comprehensive Analysis Section</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Starting Comprehensive Analysis...&quot;</span><span class="p">)</span>

<span class="c1"># Convert histories to analysis DataFrame</span>
<span class="n">histories_df</span> <span class="o">=</span> <span class="n">analyze_convergence_speed</span><span class="p">(</span><span class="n">histories</span><span class="p">)</span>

<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;</span><span class="se">\n</span><span class="s2">Convergence Analysis Results:&quot;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">histories_df</span><span class="o">.</span><span class="n">sort_values</span><span class="p">(</span><span class="s1">&#39;final_accuracy&#39;</span><span class="p">,</span> <span class="n">ascending</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span><span class="o">.</span><span class="n">head</span><span class="p">(</span><span class="mi">10</span><span class="p">))</span>

<span class="c1"># Plot sensitivity analysis for each parameter</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;</span><span class="se">\n</span><span class="s2">Generating Parameter Sensitivity Analysis...&quot;</span><span class="p">)</span>

<span class="c1"># Learning Rate Sensitivity</span>
<span class="n">lr_configs</span> <span class="o">=</span> <span class="p">[</span><span class="sa">f</span><span class="s1">&#39;lr_</span><span class="si">{</span><span class="n">lr</span><span class="si">}</span><span class="s1">&#39;</span> <span class="k">for</span> <span class="n">lr</span> <span class="ow">in</span> <span class="n">learning_rates</span><span class="p">]</span>
<span class="n">lr_df</span> <span class="o">=</span> <span class="n">histories_df</span><span class="p">[</span><span class="n">histories_df</span><span class="p">[</span><span class="s1">&#39;config&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">isin</span><span class="p">(</span><span class="n">lr_configs</span><span class="p">)]</span>
<span class="n">plot_parameter_sensitivity</span><span class="p">(</span><span class="n">lr_df</span><span class="p">,</span> <span class="s1">&#39;lr&#39;</span><span class="p">)</span>

<span class="c1"># Beta1 Sensitivity  </span>
<span class="n">beta1_configs</span> <span class="o">=</span> <span class="p">[</span><span class="sa">f</span><span class="s1">&#39;beta1_</span><span class="si">{</span><span class="n">beta1</span><span class="si">}</span><span class="s1">&#39;</span> <span class="k">for</span> <span class="n">beta1</span> <span class="ow">in</span> <span class="n">beta1_values</span><span class="p">]</span>
<span class="n">beta1_df</span> <span class="o">=</span> <span class="n">histories_df</span><span class="p">[</span><span class="n">histories_df</span><span class="p">[</span><span class="s1">&#39;config&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">isin</span><span class="p">(</span><span class="n">beta1_configs</span><span class="p">)]</span>
<span class="n">plot_parameter_sensitivity</span><span class="p">(</span><span class="n">beta1_df</span><span class="p">,</span> <span class="s1">&#39;beta1&#39;</span><span class="p">)</span>

<span class="c1"># Beta2 Sensitivity</span>
<span class="n">beta2_configs</span> <span class="o">=</span> <span class="p">[</span><span class="sa">f</span><span class="s1">&#39;beta2_</span><span class="si">{</span><span class="n">beta2</span><span class="si">}</span><span class="s1">&#39;</span> <span class="k">for</span> <span class="n">beta2</span> <span class="ow">in</span> <span class="n">beta2_values</span><span class="p">]</span>
<span class="n">beta2_df</span> <span class="o">=</span> <span class="n">histories_df</span><span class="p">[</span><span class="n">histories_df</span><span class="p">[</span><span class="s1">&#39;config&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">isin</span><span class="p">(</span><span class="n">beta2_configs</span><span class="p">)]</span>
<span class="n">plot_parameter_sensitivity</span><span class="p">(</span><span class="n">beta2_df</span><span class="p">,</span> <span class="s1">&#39;beta2&#39;</span><span class="p">)</span>

<span class="c1"># Epsilon Sensitivity</span>
<span class="n">epsilon_configs</span> <span class="o">=</span> <span class="p">[</span><span class="sa">f</span><span class="s1">&#39;epsilon_</span><span class="si">{</span><span class="n">epsilon</span><span class="si">}</span><span class="s1">&#39;</span> <span class="k">for</span> <span class="n">epsilon</span> <span class="ow">in</span> <span class="n">epsilon_values</span><span class="p">]</span>
<span class="n">epsilon_df</span> <span class="o">=</span> <span class="n">histories_df</span><span class="p">[</span><span class="n">histories_df</span><span class="p">[</span><span class="s1">&#39;config&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">isin</span><span class="p">(</span><span class="n">epsilon_configs</span><span class="p">)]</span>
<span class="n">plot_parameter_sensitivity</span><span class="p">(</span><span class="n">epsilon_df</span><span class="p">,</span> <span class="s1">&#39;epsilon&#39;</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Starting Comprehensive Analysis...

Convergence Analysis Results:
           config  convergence_epoch  final_accuracy  final_loss  stability
13  epsilon_1e-08                  4          0.9916    0.030113   0.005000
8       beta2_0.9                  4          0.9914    0.032186   0.001367
7     beta1_0.999                  9          0.9913    0.041344   0.003861
14  epsilon_1e-07                  4          0.9910    0.032020   0.009417
9      beta2_0.99                  9          0.9908    0.037060   0.007588
4       beta1_0.5                  9          0.9907    0.035426   0.006285
10    beta2_0.999                  9          0.9905    0.047078   0.006856
12  epsilon_1e-09                  4          0.9904    0.030915   0.009544
6      beta1_0.99                  9          0.9904    0.042771   0.005091
15  epsilon_1e-06                  4          0.9900    0.029238   0.006690

Generating Parameter Sensitivity Analysis...
</pre></div>
</div>
<img alt="../_images/bb23d49d2d99638a4f6cd13e3b2d2a54b09e0b287f1690c3e333f68ab3378742.png" src="../_images/bb23d49d2d99638a4f6cd13e3b2d2a54b09e0b287f1690c3e333f68ab3378742.png" />
<img alt="../_images/75367e12611d5321f898eb440b862629bf5afe4c214a355afcbba0d6968965bf.png" src="../_images/75367e12611d5321f898eb440b862629bf5afe4c214a355afcbba0d6968965bf.png" />
<img alt="../_images/cdb5838c6a0897303fff580450e2f433ec11e6ace2833d596e6e761b8ea40ffe.png" src="../_images/cdb5838c6a0897303fff580450e2f433ec11e6ace2833d596e6e761b8ea40ffe.png" />
<img alt="../_images/fcefe1d89eaae4c48f77c6a448fec7e979f5a04bed9404babc9ec06093aacda4.png" src="../_images/fcefe1d89eaae4c48f77c6a448fec7e979f5a04bed9404babc9ec06093aacda4.png" />
</div>
</div>
</section>
</section>
<section id="key-insights-and-findings">
<h2>Key Insights and Findings<a class="headerlink" href="#key-insights-and-findings" title="Link to this heading">#</a></h2>
<p>After analyzing 17 different configurations across 4 parameters, here are the most significant discoveries from our experiments.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Key Insights and Statistical Analysis</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;=&quot;</span><span class="o">*</span><span class="mi">80</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;KEY INSIGHTS AND FINDINGS&quot;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;=&quot;</span><span class="o">*</span><span class="mi">80</span><span class="p">)</span>

<span class="c1"># Find best configuration</span>
<span class="n">best_config</span> <span class="o">=</span> <span class="n">histories_df</span><span class="o">.</span><span class="n">loc</span><span class="p">[</span><span class="n">histories_df</span><span class="p">[</span><span class="s1">&#39;final_accuracy&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">idxmax</span><span class="p">()]</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;BEST OVERALL CONFIGURATION:&quot;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Configuration: </span><span class="si">{</span><span class="n">best_config</span><span class="p">[</span><span class="s1">&#39;config&#39;</span><span class="p">]</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Final Accuracy: </span><span class="si">{</span><span class="n">best_config</span><span class="p">[</span><span class="s1">&#39;final_accuracy&#39;</span><span class="p">]</span><span class="si">:</span><span class="s2">.4f</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Convergence Speed: </span><span class="si">{</span><span class="n">best_config</span><span class="p">[</span><span class="s1">&#39;convergence_epoch&#39;</span><span class="p">]</span><span class="si">}</span><span class="s2"> epochs&quot;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Training Stability: </span><span class="si">{</span><span class="n">best_config</span><span class="p">[</span><span class="s1">&#39;stability&#39;</span><span class="p">]</span><span class="si">:</span><span class="s2">.6f</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>

<span class="c1"># Statistical analysis</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;STATISTICAL ANALYSIS:&quot;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Accuracy Range: </span><span class="si">{</span><span class="n">histories_df</span><span class="p">[</span><span class="s1">&#39;final_accuracy&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">min</span><span class="p">()</span><span class="si">:</span><span class="s2">.4f</span><span class="si">}</span><span class="s2"> - </span><span class="si">{</span><span class="n">histories_df</span><span class="p">[</span><span class="s1">&#39;final_accuracy&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">max</span><span class="p">()</span><span class="si">:</span><span class="s2">.4f</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Mean Accuracy: </span><span class="si">{</span><span class="n">histories_df</span><span class="p">[</span><span class="s1">&#39;final_accuracy&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">mean</span><span class="p">()</span><span class="si">:</span><span class="s2">.4f</span><span class="si">}</span><span class="s2"> ± </span><span class="si">{</span><span class="n">histories_df</span><span class="p">[</span><span class="s1">&#39;final_accuracy&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">std</span><span class="p">()</span><span class="si">:</span><span class="s2">.4f</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Fastest Convergence: </span><span class="si">{</span><span class="n">histories_df</span><span class="p">[</span><span class="s1">&#39;convergence_epoch&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">min</span><span class="p">()</span><span class="si">}</span><span class="s2"> epochs&quot;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Most Stable: </span><span class="si">{</span><span class="n">histories_df</span><span class="o">.</span><span class="n">loc</span><span class="p">[</span><span class="n">histories_df</span><span class="p">[</span><span class="s1">&#39;stability&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">idxmin</span><span class="p">()][</span><span class="s1">&#39;config&#39;</span><span class="p">]</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>

<span class="c1"># Parameter-specific insights</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;PARAMETER-SPECIFIC INSIGHTS:&quot;</span><span class="p">)</span>

<span class="c1"># Learning Rate Insights</span>
<span class="n">lr_best</span> <span class="o">=</span> <span class="n">lr_df</span><span class="o">.</span><span class="n">loc</span><span class="p">[</span><span class="n">lr_df</span><span class="p">[</span><span class="s1">&#39;final_accuracy&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">idxmax</span><span class="p">()]</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;• Optimal Learning Rate: </span><span class="si">{</span><span class="n">lr_best</span><span class="p">[</span><span class="s1">&#39;config&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">split</span><span class="p">(</span><span class="s1">&#39;_&#39;</span><span class="p">)[</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span><span class="si">}</span><span class="s2"> (Accuracy: </span><span class="si">{</span><span class="n">lr_best</span><span class="p">[</span><span class="s1">&#39;final_accuracy&#39;</span><span class="p">]</span><span class="si">:</span><span class="s2">.4f</span><span class="si">}</span><span class="s2">)&quot;</span><span class="p">)</span>

<span class="c1"># Beta1 Insights</span>
<span class="n">beta1_best</span> <span class="o">=</span> <span class="n">beta1_df</span><span class="o">.</span><span class="n">loc</span><span class="p">[</span><span class="n">beta1_df</span><span class="p">[</span><span class="s1">&#39;final_accuracy&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">idxmax</span><span class="p">()]</span>
<span class="n">beta1_default</span> <span class="o">=</span> <span class="n">beta1_df</span><span class="p">[</span><span class="n">beta1_df</span><span class="p">[</span><span class="s1">&#39;config&#39;</span><span class="p">]</span> <span class="o">==</span> <span class="s1">&#39;beta1_0.9&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">iloc</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
<span class="n">improvement</span> <span class="o">=</span> <span class="p">(</span><span class="n">beta1_best</span><span class="p">[</span><span class="s1">&#39;final_accuracy&#39;</span><span class="p">]</span> <span class="o">-</span> <span class="n">beta1_default</span><span class="p">[</span><span class="s1">&#39;final_accuracy&#39;</span><span class="p">])</span> <span class="o">*</span> <span class="mi">100</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;• Beta1 Optimization: Default (0.9) vs Best (</span><span class="si">{</span><span class="n">beta1_best</span><span class="p">[</span><span class="s1">&#39;config&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">split</span><span class="p">(</span><span class="s1">&#39;_&#39;</span><span class="p">)[</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span><span class="si">}</span><span class="s2">)&quot;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;  Improvement: </span><span class="si">{</span><span class="n">improvement</span><span class="si">:</span><span class="s2">+.3f</span><span class="si">}</span><span class="s2">%&quot;</span><span class="p">)</span>

<span class="c1"># Epsilon Insights</span>
<span class="n">epsilon_best</span> <span class="o">=</span> <span class="n">epsilon_df</span><span class="o">.</span><span class="n">loc</span><span class="p">[</span><span class="n">epsilon_df</span><span class="p">[</span><span class="s1">&#39;final_accuracy&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">idxmax</span><span class="p">()]</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;• Epsilon Sweet Spot: </span><span class="si">{</span><span class="n">epsilon_best</span><span class="p">[</span><span class="s1">&#39;config&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">split</span><span class="p">(</span><span class="s1">&#39;_&#39;</span><span class="p">)[</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;  Challenges &#39;epsilon is just for numerical stability&#39; assumption&quot;</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>================================================================================
KEY INSIGHTS AND FINDINGS
================================================================================
BEST OVERALL CONFIGURATION:
Configuration: epsilon_1e-08
Final Accuracy: 0.9916
Convergence Speed: 4 epochs
Training Stability: 0.005000
STATISTICAL ANALYSIS:
Accuracy Range: 0.1028 - 0.9916
Mean Accuracy: 0.9369 ± 0.2150
Fastest Convergence: 0 epochs
Most Stable: beta2_0.9
PARAMETER-SPECIFIC INSIGHTS:
• Optimal Learning Rate: 0.001 (Accuracy: 0.9891)
• Beta1 Optimization: Default (0.9) vs Best (0.999)
  Improvement: +0.170%
• Epsilon Sweet Spot: 1e-08
  Challenges &#39;epsilon is just for numerical stability&#39; assumption
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Final Performance Analysis</span>
<span class="k">def</span><span class="w"> </span><span class="nf">plot_final_performance</span><span class="p">(</span><span class="n">histories</span><span class="p">):</span>
    <span class="n">fig</span><span class="p">,</span> <span class="p">(</span><span class="n">ax1</span><span class="p">,</span> <span class="n">ax2</span><span class="p">)</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">subplots</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">15</span><span class="p">,</span> <span class="mi">6</span><span class="p">))</span>
    
    <span class="c1"># Extract final accuracies and losses</span>
    <span class="n">final_accuracies</span> <span class="o">=</span> <span class="p">[]</span>
    <span class="n">final_losses</span> <span class="o">=</span> <span class="p">[]</span>
    <span class="n">labels</span> <span class="o">=</span> <span class="p">[]</span>
    
    <span class="k">for</span> <span class="n">key</span> <span class="ow">in</span> <span class="n">histories</span><span class="o">.</span><span class="n">keys</span><span class="p">():</span>
        <span class="n">history</span> <span class="o">=</span> <span class="n">histories</span><span class="p">[</span><span class="n">key</span><span class="p">]</span>
        <span class="n">final_acc</span> <span class="o">=</span> <span class="n">history</span><span class="o">.</span><span class="n">history</span><span class="p">[</span><span class="s1">&#39;val_accuracy&#39;</span><span class="p">][</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span>
        <span class="n">final_loss</span> <span class="o">=</span> <span class="n">history</span><span class="o">.</span><span class="n">history</span><span class="p">[</span><span class="s1">&#39;val_loss&#39;</span><span class="p">][</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span>
        <span class="n">final_accuracies</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">final_acc</span><span class="p">)</span>
        <span class="n">final_losses</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">final_loss</span><span class="p">)</span>
        <span class="n">labels</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">key</span><span class="p">)</span>
    
    <span class="c1"># Sort by accuracy for better visualization</span>
    <span class="n">sorted_indices</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">argsort</span><span class="p">(</span><span class="n">final_accuracies</span><span class="p">)</span>
    <span class="n">final_accuracies</span> <span class="o">=</span> <span class="p">[</span><span class="n">final_accuracies</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="n">sorted_indices</span><span class="p">]</span>
    <span class="n">final_losses</span> <span class="o">=</span> <span class="p">[</span><span class="n">final_losses</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="n">sorted_indices</span><span class="p">]</span>
    <span class="n">labels</span> <span class="o">=</span> <span class="p">[</span><span class="n">labels</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="n">sorted_indices</span><span class="p">]</span>
    
    <span class="c1"># Accuracy bar plot</span>
    <span class="n">bars</span> <span class="o">=</span> <span class="n">ax1</span><span class="o">.</span><span class="n">barh</span><span class="p">(</span><span class="nb">range</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">labels</span><span class="p">)),</span> <span class="n">final_accuracies</span><span class="p">,</span> <span class="n">color</span><span class="o">=</span><span class="s1">&#39;skyblue&#39;</span><span class="p">)</span>
    <span class="n">ax1</span><span class="o">.</span><span class="n">set_yticks</span><span class="p">(</span><span class="nb">range</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">labels</span><span class="p">)))</span>
    <span class="n">ax1</span><span class="o">.</span><span class="n">set_yticklabels</span><span class="p">(</span><span class="n">labels</span><span class="p">)</span>
    <span class="n">ax1</span><span class="o">.</span><span class="n">set_xlabel</span><span class="p">(</span><span class="s1">&#39;Final Validation Accuracy&#39;</span><span class="p">)</span>
    <span class="n">ax1</span><span class="o">.</span><span class="n">set_title</span><span class="p">(</span><span class="s1">&#39;Final Performance Comparison&#39;</span><span class="p">,</span> <span class="n">fontweight</span><span class="o">=</span><span class="s1">&#39;bold&#39;</span><span class="p">)</span>
    
    <span class="c1"># Add value labels on bars</span>
    <span class="k">for</span> <span class="n">bar</span><span class="p">,</span> <span class="n">acc</span> <span class="ow">in</span> <span class="nb">zip</span><span class="p">(</span><span class="n">bars</span><span class="p">,</span> <span class="n">final_accuracies</span><span class="p">):</span>
        <span class="n">ax1</span><span class="o">.</span><span class="n">text</span><span class="p">(</span><span class="n">bar</span><span class="o">.</span><span class="n">get_width</span><span class="p">()</span> <span class="o">+</span> <span class="mf">0.01</span><span class="p">,</span> <span class="n">bar</span><span class="o">.</span><span class="n">get_y</span><span class="p">()</span> <span class="o">+</span> <span class="n">bar</span><span class="o">.</span><span class="n">get_height</span><span class="p">()</span><span class="o">/</span><span class="mi">2</span><span class="p">,</span> 
                <span class="sa">f</span><span class="s1">&#39;</span><span class="si">{</span><span class="n">acc</span><span class="si">:</span><span class="s1">.3f</span><span class="si">}</span><span class="s1">&#39;</span><span class="p">,</span> <span class="n">ha</span><span class="o">=</span><span class="s1">&#39;left&#39;</span><span class="p">,</span> <span class="n">va</span><span class="o">=</span><span class="s1">&#39;center&#39;</span><span class="p">)</span>
    
    <span class="c1"># Loss bar plot</span>
    <span class="n">bars2</span> <span class="o">=</span> <span class="n">ax2</span><span class="o">.</span><span class="n">barh</span><span class="p">(</span><span class="nb">range</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">labels</span><span class="p">)),</span> <span class="n">final_losses</span><span class="p">,</span> <span class="n">color</span><span class="o">=</span><span class="s1">&#39;lightcoral&#39;</span><span class="p">)</span>
    <span class="n">ax2</span><span class="o">.</span><span class="n">set_yticks</span><span class="p">(</span><span class="nb">range</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">labels</span><span class="p">)))</span>
    <span class="n">ax2</span><span class="o">.</span><span class="n">set_yticklabels</span><span class="p">(</span><span class="n">labels</span><span class="p">)</span>
    <span class="n">ax2</span><span class="o">.</span><span class="n">set_xlabel</span><span class="p">(</span><span class="s1">&#39;Final Validation Loss&#39;</span><span class="p">)</span>
    <span class="n">ax2</span><span class="o">.</span><span class="n">set_title</span><span class="p">(</span><span class="s1">&#39;Final Loss Comparison&#39;</span><span class="p">,</span> <span class="n">fontweight</span><span class="o">=</span><span class="s1">&#39;bold&#39;</span><span class="p">)</span>
    
    <span class="c1"># Add value labels on bars</span>
    <span class="k">for</span> <span class="n">bar</span><span class="p">,</span> <span class="n">loss</span> <span class="ow">in</span> <span class="nb">zip</span><span class="p">(</span><span class="n">bars2</span><span class="p">,</span> <span class="n">final_losses</span><span class="p">):</span>
        <span class="n">ax2</span><span class="o">.</span><span class="n">text</span><span class="p">(</span><span class="n">bar</span><span class="o">.</span><span class="n">get_width</span><span class="p">()</span> <span class="o">+</span> <span class="mf">0.01</span><span class="p">,</span> <span class="n">bar</span><span class="o">.</span><span class="n">get_y</span><span class="p">()</span> <span class="o">+</span> <span class="n">bar</span><span class="o">.</span><span class="n">get_height</span><span class="p">()</span><span class="o">/</span><span class="mi">2</span><span class="p">,</span> 
                <span class="sa">f</span><span class="s1">&#39;</span><span class="si">{</span><span class="n">loss</span><span class="si">:</span><span class="s1">.3f</span><span class="si">}</span><span class="s1">&#39;</span><span class="p">,</span> <span class="n">ha</span><span class="o">=</span><span class="s1">&#39;left&#39;</span><span class="p">,</span> <span class="n">va</span><span class="o">=</span><span class="s1">&#39;center&#39;</span><span class="p">)</span>
    
    <span class="n">plt</span><span class="o">.</span><span class="n">tight_layout</span><span class="p">()</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>

<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Generating final performance analysis...&quot;</span><span class="p">)</span>
<span class="n">plot_final_performance</span><span class="p">(</span><span class="n">histories</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Generating final performance analysis...
</pre></div>
</div>
<img alt="../_images/30676b9617d4c928a84caf675a3cdac05d8a424bf4cda1024348c66045c88419.png" src="../_images/30676b9617d4c928a84caf675a3cdac05d8a424bf4cda1024348c66045c88419.png" />
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Cell 11: Detailed Results Analysis</span>
<span class="k">def</span><span class="w"> </span><span class="nf">analyze_results</span><span class="p">(</span><span class="n">histories</span><span class="p">):</span>
    <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;KEY INSIGHTS FROM EXPERIMENTS:&quot;</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;=&quot;</span> <span class="o">*</span> <span class="mi">50</span><span class="p">)</span>
    
    <span class="n">best_acc</span> <span class="o">=</span> <span class="mi">0</span>
    <span class="n">best_config</span> <span class="o">=</span> <span class="s2">&quot;&quot;</span>
    
    <span class="c1"># Group by parameter type for better analysis</span>
    <span class="n">param_groups</span> <span class="o">=</span> <span class="p">{</span>
        <span class="s1">&#39;Learning Rates&#39;</span><span class="p">:</span> <span class="p">[],</span>
        <span class="s1">&#39;Beta1 Values&#39;</span><span class="p">:</span> <span class="p">[],</span>
        <span class="s1">&#39;Beta2 Values&#39;</span><span class="p">:</span> <span class="p">[],</span>
        <span class="s1">&#39;Epsilon Values&#39;</span><span class="p">:</span> <span class="p">[]</span>
    <span class="p">}</span>
    
    <span class="k">for</span> <span class="n">key</span><span class="p">,</span> <span class="n">history</span> <span class="ow">in</span> <span class="n">histories</span><span class="o">.</span><span class="n">items</span><span class="p">():</span>
        <span class="n">final_acc</span> <span class="o">=</span> <span class="n">history</span><span class="o">.</span><span class="n">history</span><span class="p">[</span><span class="s1">&#39;val_accuracy&#39;</span><span class="p">][</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span>
        <span class="n">final_loss</span> <span class="o">=</span> <span class="n">history</span><span class="o">.</span><span class="n">history</span><span class="p">[</span><span class="s1">&#39;val_loss&#39;</span><span class="p">][</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span>
        
        <span class="k">if</span> <span class="n">final_acc</span> <span class="o">&gt;</span> <span class="n">best_acc</span><span class="p">:</span>
            <span class="n">best_acc</span> <span class="o">=</span> <span class="n">final_acc</span>
            <span class="n">best_config</span> <span class="o">=</span> <span class="n">key</span>
        
        <span class="c1"># Categorize by parameter type</span>
        <span class="k">if</span> <span class="n">key</span><span class="o">.</span><span class="n">startswith</span><span class="p">(</span><span class="s1">&#39;lr_&#39;</span><span class="p">):</span>
            <span class="n">param_groups</span><span class="p">[</span><span class="s1">&#39;Learning Rates&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">append</span><span class="p">((</span><span class="n">key</span><span class="p">,</span> <span class="n">final_acc</span><span class="p">,</span> <span class="n">final_loss</span><span class="p">))</span>
        <span class="k">elif</span> <span class="n">key</span><span class="o">.</span><span class="n">startswith</span><span class="p">(</span><span class="s1">&#39;beta1_&#39;</span><span class="p">):</span>
            <span class="n">param_groups</span><span class="p">[</span><span class="s1">&#39;Beta1 Values&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">append</span><span class="p">((</span><span class="n">key</span><span class="p">,</span> <span class="n">final_acc</span><span class="p">,</span> <span class="n">final_loss</span><span class="p">))</span>
        <span class="k">elif</span> <span class="n">key</span><span class="o">.</span><span class="n">startswith</span><span class="p">(</span><span class="s1">&#39;beta2_&#39;</span><span class="p">):</span>
            <span class="n">param_groups</span><span class="p">[</span><span class="s1">&#39;Beta2 Values&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">append</span><span class="p">((</span><span class="n">key</span><span class="p">,</span> <span class="n">final_acc</span><span class="p">,</span> <span class="n">final_loss</span><span class="p">))</span>
        <span class="k">elif</span> <span class="n">key</span><span class="o">.</span><span class="n">startswith</span><span class="p">(</span><span class="s1">&#39;epsilon_&#39;</span><span class="p">):</span>
            <span class="n">param_groups</span><span class="p">[</span><span class="s1">&#39;Epsilon Values&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">append</span><span class="p">((</span><span class="n">key</span><span class="p">,</span> <span class="n">final_acc</span><span class="p">,</span> <span class="n">final_loss</span><span class="p">))</span>
    
    <span class="c1"># Print results by category</span>
    <span class="k">for</span> <span class="n">category</span><span class="p">,</span> <span class="n">results</span> <span class="ow">in</span> <span class="n">param_groups</span><span class="o">.</span><span class="n">items</span><span class="p">():</span>
        <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;</span><span class="se">\\</span><span class="s2">n</span><span class="si">{</span><span class="n">category</span><span class="si">}</span><span class="s2">:&quot;</span><span class="p">)</span>
        <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;-&quot;</span> <span class="o">*</span> <span class="mi">30</span><span class="p">)</span>
        <span class="k">for</span> <span class="n">key</span><span class="p">,</span> <span class="n">acc</span><span class="p">,</span> <span class="n">loss</span> <span class="ow">in</span> <span class="nb">sorted</span><span class="p">(</span><span class="n">results</span><span class="p">,</span> <span class="n">key</span><span class="o">=</span><span class="k">lambda</span> <span class="n">x</span><span class="p">:</span> <span class="n">x</span><span class="p">[</span><span class="mi">1</span><span class="p">],</span> <span class="n">reverse</span><span class="o">=</span><span class="kc">True</span><span class="p">):</span>
            <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;  </span><span class="si">{</span><span class="n">key</span><span class="si">:</span><span class="s2">20</span><span class="si">}</span><span class="s2"> | Accuracy: </span><span class="si">{</span><span class="n">acc</span><span class="si">:</span><span class="s2">.4f</span><span class="si">}</span><span class="s2"> | Loss: </span><span class="si">{</span><span class="n">loss</span><span class="si">:</span><span class="s2">.4f</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
    
    <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;</span><span class="se">\\</span><span class="s2">n&quot;</span> <span class="o">+</span> <span class="s2">&quot;=&quot;</span> <span class="o">*</span> <span class="mi">50</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;BEST OVERALL CONFIGURATION: </span><span class="si">{</span><span class="n">best_config</span><span class="si">}</span><span class="s2"> with accuracy </span><span class="si">{</span><span class="n">best_acc</span><span class="si">:</span><span class="s2">.4f</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;=&quot;</span> <span class="o">*</span> <span class="mi">50</span><span class="p">)</span>

<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Detailed Results Analysis:&quot;</span><span class="p">)</span>
<span class="n">analyze_results</span><span class="p">(</span><span class="n">histories</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Detailed Results Analysis:
KEY INSIGHTS FROM EXPERIMENTS:
==================================================
\nLearning Rates:
------------------------------
  lr_0.001             | Accuracy: 0.9891 | Loss: 0.0452
  lr_0.0001            | Accuracy: 0.9858 | Loss: 0.0405
  lr_0.01              | Accuracy: 0.9774 | Loss: 0.0923
  lr_0.1               | Accuracy: 0.1028 | Loss: 2.3146
\nBeta1 Values:
------------------------------
  beta1_0.999          | Accuracy: 0.9913 | Loss: 0.0413
  beta1_0.5            | Accuracy: 0.9907 | Loss: 0.0354
  beta1_0.99           | Accuracy: 0.9904 | Loss: 0.0428
  beta1_0.9            | Accuracy: 0.9896 | Loss: 0.0394
\nBeta2 Values:
------------------------------
  beta2_0.9            | Accuracy: 0.9914 | Loss: 0.0322
  beta2_0.99           | Accuracy: 0.9908 | Loss: 0.0371
  beta2_0.999          | Accuracy: 0.9905 | Loss: 0.0471
  beta2_0.9999         | Accuracy: 0.9882 | Loss: 0.0450
\nEpsilon Values:
------------------------------
  epsilon_1e-08        | Accuracy: 0.9916 | Loss: 0.0301
  epsilon_1e-07        | Accuracy: 0.9910 | Loss: 0.0320
  epsilon_1e-09        | Accuracy: 0.9904 | Loss: 0.0309
  epsilon_1e-06        | Accuracy: 0.9900 | Loss: 0.0292
  epsilon_1e-05        | Accuracy: 0.9861 | Loss: 0.0439
\n==================================================
BEST OVERALL CONFIGURATION: epsilon_1e-08 with accuracy 0.9916
==================================================
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Summary of what we learned</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;&quot;&quot;</span>
<span class="s2"> SUMMARY OF ADAM OPTIMIZER EXPERIMENTS:</span>

<span class="s2">WHAT WE TESTED:</span>
<span class="s2">• Learning Rate (α): Controls step size in parameter updates</span>
<span class="s2">• Beta1 (β1): Controls momentum - how much past gradients influence current update</span>
<span class="s2">• Beta2 (β2): Controls squared gradient decay - adaptive learning rate behavior  </span>
<span class="s2">• Epsilon (ε): Small constant to prevent division by zero</span>

<span class="s2">KEY FINDINGS:</span>
<span class="s2">1. Learning Rate: Too high (0.1) causes instability, moderate values (0.001-0.01) work best</span>
<span class="s2">2. Beta1: Moderate values (0.9) provide good momentum without overshooting</span>
<span class="s2">3. Beta2: Higher values (0.999) work well for stable second moment estimation</span>
<span class="s2">4. Epsilon: Small changes have minor effects, but extreme values can impact performance</span>

<span class="s2">RECOMMENDED DEFAULTS:</span>
<span class="s2">• Learning Rate: 0.001</span>
<span class="s2">• Beta1: 0.9  </span>
<span class="s2">• Beta2: 0.999</span>
<span class="s2">• Epsilon: 1e-7</span>

<span class="s2">These experiments show why Adam&#39;s default parameters work well across many problems!</span>
<span class="s2">&quot;&quot;&quot;</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span> SUMMARY OF ADAM OPTIMIZER EXPERIMENTS:

WHAT WE TESTED:
• Learning Rate (α): Controls step size in parameter updates
• Beta1 (β1): Controls momentum - how much past gradients influence current update
• Beta2 (β2): Controls squared gradient decay - adaptive learning rate behavior  
• Epsilon (ε): Small constant to prevent division by zero

KEY FINDINGS:
1. Learning Rate: Too high (0.1) causes instability, moderate values (0.001-0.01) work best
2. Beta1: Moderate values (0.9) provide good momentum without overshooting
3. Beta2: Higher values (0.999) work well for stable second moment estimation
4. Epsilon: Small changes have minor effects, but extreme values can impact performance

RECOMMENDED DEFAULTS:
• Learning Rate: 0.001
• Beta1: 0.9  
• Beta2: 0.999
• Epsilon: 1e-7

These experiments show why Adam&#39;s default parameters work well across many problems!
</pre></div>
</div>
</div>
</div>
</section>
<section id="practical-recommendations-for-practitioners">
<h2>Practical Recommendations for Practitioners<a class="headerlink" href="#practical-recommendations-for-practitioners" title="Link to this heading">#</a></h2>
<p>Based on our experimental results, here are tailored Adam configurations for different scenarios you might encounter in practice.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Practical Recommendations</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;</span><span class="se">\n</span><span class="s2">&quot;</span> <span class="o">+</span> <span class="s2">&quot;=&quot;</span><span class="o">*</span><span class="mi">80</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;PRACTICAL RECOMMENDATIONS&quot;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;=&quot;</span><span class="o">*</span><span class="mi">80</span><span class="p">)</span>

<span class="n">recommendations</span> <span class="o">=</span> <span class="p">{</span>
    <span class="s1">&#39;scenario&#39;</span><span class="p">:</span> <span class="p">[</span><span class="s1">&#39;Default Quick Training&#39;</span><span class="p">,</span> <span class="s1">&#39;Stable Training&#39;</span><span class="p">,</span> <span class="s1">&#39;Fast Convergence&#39;</span><span class="p">,</span> <span class="s1">&#39;High Precision&#39;</span><span class="p">],</span>
    <span class="s1">&#39;learning_rate&#39;</span><span class="p">:</span> <span class="p">[</span><span class="s1">&#39;1e-3&#39;</span><span class="p">,</span> <span class="s1">&#39;1e-4&#39;</span><span class="p">,</span> <span class="s1">&#39;1e-2&#39;</span><span class="p">,</span> <span class="s1">&#39;5e-4&#39;</span><span class="p">],</span>
    <span class="s1">&#39;beta_1&#39;</span><span class="p">:</span> <span class="p">[</span><span class="s1">&#39;0.9&#39;</span><span class="p">,</span> <span class="s1">&#39;0.95&#39;</span><span class="p">,</span> <span class="s1">&#39;0.8&#39;</span><span class="p">,</span> <span class="s1">&#39;0.9&#39;</span><span class="p">],</span>
    <span class="s1">&#39;beta_2&#39;</span><span class="p">:</span> <span class="p">[</span><span class="s1">&#39;0.999&#39;</span><span class="p">,</span> <span class="s1">&#39;0.999&#39;</span><span class="p">,</span> <span class="s1">&#39;0.99&#39;</span><span class="p">,</span> <span class="s1">&#39;0.9999&#39;</span><span class="p">],</span>
    <span class="s1">&#39;epsilon&#39;</span><span class="p">:</span> <span class="p">[</span><span class="s1">&#39;1e-7&#39;</span><span class="p">,</span> <span class="s1">&#39;1e-7&#39;</span><span class="p">,</span> <span class="s1">&#39;1e-8&#39;</span><span class="p">,</span> <span class="s1">&#39;1e-9&#39;</span><span class="p">],</span>
    <span class="s1">&#39;rationale&#39;</span><span class="p">:</span> <span class="p">[</span>
        <span class="s1">&#39;Balanced settings for most problems&#39;</span><span class="p">,</span>
        <span class="s1">&#39;Slower but more reliable convergence&#39;</span><span class="p">,</span>
        <span class="s1">&#39;Aggressive settings for simple problems&#39;</span><span class="p">,</span>
        <span class="s1">&#39;For tasks requiring high numerical precision&#39;</span>
    <span class="p">]</span>
<span class="p">}</span>

<span class="n">recommendations_df</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">(</span><span class="n">recommendations</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;</span><span class="se">\n</span><span class="s2">Recommended Adam Configurations for Different Scenarios:&quot;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">recommendations_df</span><span class="o">.</span><span class="n">to_string</span><span class="p">(</span><span class="n">index</span><span class="o">=</span><span class="kc">False</span><span class="p">))</span>

<span class="c1"># Code template for recommendations</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;IMPLEMENTATION TEMPLATE:&quot;</span><span class="p">)</span>

<span class="n">optimizer_configs</span> <span class="o">=</span> <span class="p">{</span>
    <span class="s1">&#39;default_quick&#39;</span><span class="p">:</span> <span class="p">{</span><span class="s1">&#39;lr&#39;</span><span class="p">:</span> <span class="mf">1e-3</span><span class="p">,</span> <span class="s1">&#39;beta_1&#39;</span><span class="p">:</span> <span class="mf">0.9</span><span class="p">,</span> <span class="s1">&#39;beta_2&#39;</span><span class="p">:</span> <span class="mf">0.999</span><span class="p">,</span> <span class="s1">&#39;epsilon&#39;</span><span class="p">:</span> <span class="mf">1e-7</span><span class="p">},</span>
    <span class="s1">&#39;stable_training&#39;</span><span class="p">:</span> <span class="p">{</span><span class="s1">&#39;lr&#39;</span><span class="p">:</span> <span class="mf">1e-4</span><span class="p">,</span> <span class="s1">&#39;beta_1&#39;</span><span class="p">:</span> <span class="mf">0.95</span><span class="p">,</span> <span class="s1">&#39;beta_2&#39;</span><span class="p">:</span> <span class="mf">0.999</span><span class="p">,</span> <span class="s1">&#39;epsilon&#39;</span><span class="p">:</span> <span class="mf">1e-7</span><span class="p">},</span>
    <span class="s1">&#39;fast_convergence&#39;</span><span class="p">:</span> <span class="p">{</span><span class="s1">&#39;lr&#39;</span><span class="p">:</span> <span class="mf">1e-2</span><span class="p">,</span> <span class="s1">&#39;beta_1&#39;</span><span class="p">:</span> <span class="mf">0.8</span><span class="p">,</span> <span class="s1">&#39;beta_2&#39;</span><span class="p">:</span> <span class="mf">0.99</span><span class="p">,</span> <span class="s1">&#39;epsilon&#39;</span><span class="p">:</span> <span class="mf">1e-8</span><span class="p">},</span>
    <span class="s1">&#39;high_precision&#39;</span><span class="p">:</span> <span class="p">{</span><span class="s1">&#39;lr&#39;</span><span class="p">:</span> <span class="mf">5e-4</span><span class="p">,</span> <span class="s1">&#39;beta_1&#39;</span><span class="p">:</span> <span class="mf">0.9</span><span class="p">,</span> <span class="s1">&#39;beta_2&#39;</span><span class="p">:</span> <span class="mf">0.9999</span><span class="p">,</span> <span class="s1">&#39;epsilon&#39;</span><span class="p">:</span> <span class="mf">1e-9</span><span class="p">},</span>
<span class="p">}</span>

<span class="k">for</span> <span class="n">scenario</span><span class="p">,</span> <span class="n">config</span> <span class="ow">in</span> <span class="n">optimizer_configs</span><span class="o">.</span><span class="n">items</span><span class="p">():</span>
    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;</span><span class="se">\n</span><span class="s2"># </span><span class="si">{</span><span class="n">scenario</span><span class="o">.</span><span class="n">replace</span><span class="p">(</span><span class="s1">&#39;_&#39;</span><span class="p">,</span><span class="w"> </span><span class="s1">&#39; &#39;</span><span class="p">)</span><span class="o">.</span><span class="n">title</span><span class="p">()</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;optimizer = tf.keras.optimizers.Adam(&quot;</span><span class="p">)</span>
    <span class="k">for</span> <span class="n">param</span><span class="p">,</span> <span class="n">value</span> <span class="ow">in</span> <span class="n">config</span><span class="o">.</span><span class="n">items</span><span class="p">():</span>
        <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;    </span><span class="si">{</span><span class="n">param</span><span class="si">}</span><span class="s2">=</span><span class="si">{</span><span class="n">value</span><span class="si">}</span><span class="s2">,&quot;</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;)&quot;</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>================================================================================
PRACTICAL RECOMMENDATIONS
================================================================================

Recommended Adam Configurations for Different Scenarios:
              scenario learning_rate beta_1 beta_2 epsilon                                    rationale
Default Quick Training          1e-3    0.9  0.999    1e-7          Balanced settings for most problems
       Stable Training          1e-4   0.95  0.999    1e-7         Slower but more reliable convergence
      Fast Convergence          1e-2    0.8   0.99    1e-8      Aggressive settings for simple problems
        High Precision          5e-4    0.9 0.9999    1e-9 For tasks requiring high numerical precision
IMPLEMENTATION TEMPLATE:

# Default Quick
optimizer = tf.keras.optimizers.Adam(
    lr=0.001,
    beta_1=0.9,
    beta_2=0.999,
    epsilon=1e-07,
)

# Stable Training
optimizer = tf.keras.optimizers.Adam(
    lr=0.0001,
    beta_1=0.95,
    beta_2=0.999,
    epsilon=1e-07,
)

# Fast Convergence
optimizer = tf.keras.optimizers.Adam(
    lr=0.01,
    beta_1=0.8,
    beta_2=0.99,
    epsilon=1e-08,
)

# High Precision
optimizer = tf.keras.optimizers.Adam(
    lr=0.0005,
    beta_1=0.9,
    beta_2=0.9999,
    epsilon=1e-09,
)
</pre></div>
</div>
</div>
</div>
</section>
<section id="understanding-adam-through-code">
<h2>Understanding Adam Through Code<a class="headerlink" href="#understanding-adam-through-code" title="Link to this heading">#</a></h2>
<p>The custom implementation above demonstrates Adam’s core mechanics:</p>
<ol class="arabic simple">
<li><p><strong>Momentum Tracking</strong>: Maintains running averages of gradients</p></li>
<li><p><strong>Bias Correction</strong>: Accounts for zero-initialization of moment estimates</p></li>
<li><p><strong>Adaptive Learning</strong>: Scales updates based on gradient magnitudes</p></li>
</ol>
<p>This hands-on approach helps understand why each parameter matters.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Custom Adam Implementation for Deep Understanding</span>
<span class="k">class</span><span class="w"> </span><span class="nc">CustomAdam</span><span class="p">:</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Simplified Adam optimizer implementation to demonstrate the algorithm mechanics</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="k">def</span><span class="w"> </span><span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">lr</span><span class="o">=</span><span class="mf">0.001</span><span class="p">,</span> <span class="n">beta1</span><span class="o">=</span><span class="mf">0.9</span><span class="p">,</span> <span class="n">beta2</span><span class="o">=</span><span class="mf">0.999</span><span class="p">,</span> <span class="n">epsilon</span><span class="o">=</span><span class="mf">1e-8</span><span class="p">):</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">lr</span> <span class="o">=</span> <span class="n">lr</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">beta1</span> <span class="o">=</span> <span class="n">beta1</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">beta2</span> <span class="o">=</span> <span class="n">beta2</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">epsilon</span> <span class="o">=</span> <span class="n">epsilon</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">m</span> <span class="o">=</span> <span class="kc">None</span>  <span class="c1"># First moment vector</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">v</span> <span class="o">=</span> <span class="kc">None</span>  <span class="c1"># Second moment vector</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">t</span> <span class="o">=</span> <span class="mi">0</span>     <span class="c1"># Timestep</span>
        
    <span class="k">def</span><span class="w"> </span><span class="nf">apply_gradients</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">grads_and_vars</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Apply gradients to variables using Adam update rule&quot;&quot;&quot;</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">m</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
            <span class="c1"># Initialize moment vectors</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">m</span> <span class="o">=</span> <span class="p">[</span><span class="n">tf</span><span class="o">.</span><span class="n">zeros_like</span><span class="p">(</span><span class="n">var</span><span class="p">)</span> <span class="k">for</span> <span class="n">_</span><span class="p">,</span> <span class="n">var</span> <span class="ow">in</span> <span class="n">grads_and_vars</span><span class="p">]</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">v</span> <span class="o">=</span> <span class="p">[</span><span class="n">tf</span><span class="o">.</span><span class="n">zeros_like</span><span class="p">(</span><span class="n">var</span><span class="p">)</span> <span class="k">for</span> <span class="n">_</span><span class="p">,</span> <span class="n">var</span> <span class="ow">in</span> <span class="n">grads_and_vars</span><span class="p">]</span>
        
        <span class="bp">self</span><span class="o">.</span><span class="n">t</span> <span class="o">+=</span> <span class="mi">1</span>
        
        <span class="n">updated_vars</span> <span class="o">=</span> <span class="p">[]</span>
        
        <span class="k">for</span> <span class="n">i</span><span class="p">,</span> <span class="p">(</span><span class="n">grad</span><span class="p">,</span> <span class="n">var</span><span class="p">)</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">grads_and_vars</span><span class="p">):</span>
            <span class="k">if</span> <span class="n">grad</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
                <span class="k">continue</span>
                
            <span class="c1"># Update biased first moment estimate</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">m</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">beta1</span> <span class="o">*</span> <span class="bp">self</span><span class="o">.</span><span class="n">m</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="o">+</span> <span class="p">(</span><span class="mi">1</span> <span class="o">-</span> <span class="bp">self</span><span class="o">.</span><span class="n">beta1</span><span class="p">)</span> <span class="o">*</span> <span class="n">grad</span>
            
            <span class="c1"># Update biased second raw moment estimate</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">v</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">beta2</span> <span class="o">*</span> <span class="bp">self</span><span class="o">.</span><span class="n">v</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="o">+</span> <span class="p">(</span><span class="mi">1</span> <span class="o">-</span> <span class="bp">self</span><span class="o">.</span><span class="n">beta2</span><span class="p">)</span> <span class="o">*</span> <span class="n">tf</span><span class="o">.</span><span class="n">square</span><span class="p">(</span><span class="n">grad</span><span class="p">)</span>
            
            <span class="c1"># Compute bias-corrected first moment estimate</span>
            <span class="n">m_hat</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">m</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="o">/</span> <span class="p">(</span><span class="mi">1</span> <span class="o">-</span> <span class="n">tf</span><span class="o">.</span><span class="n">pow</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">beta1</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">t</span><span class="p">))</span>
            
            <span class="c1"># Compute bias-corrected second raw moment estimate</span>
            <span class="n">v_hat</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">v</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="o">/</span> <span class="p">(</span><span class="mi">1</span> <span class="o">-</span> <span class="n">tf</span><span class="o">.</span><span class="n">pow</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">beta2</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">t</span><span class="p">))</span>
            
            <span class="c1"># Update parameters</span>
            <span class="n">var_update</span> <span class="o">=</span> <span class="n">var</span> <span class="o">-</span> <span class="bp">self</span><span class="o">.</span><span class="n">lr</span> <span class="o">*</span> <span class="n">m_hat</span> <span class="o">/</span> <span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">sqrt</span><span class="p">(</span><span class="n">v_hat</span><span class="p">)</span> <span class="o">+</span> <span class="bp">self</span><span class="o">.</span><span class="n">epsilon</span><span class="p">)</span>
            <span class="n">updated_vars</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">var_update</span><span class="p">)</span>
        
        <span class="k">return</span> <span class="n">updated_vars</span>

<span class="c1"># Test the custom implementation</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Custom Adam implementation complete!&quot;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;This demonstrates the actual mathematical operations behind Adam:&quot;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;1. Maintains moving averages of gradients (m) and squared gradients (v)&quot;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;2. Applies bias correction to account for initialization&quot;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;3. Uses adaptive learning rates based on gradient magnitudes&quot;</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Custom Adam implementation complete!
This demonstrates the actual mathematical operations behind Adam:
1. Maintains moving averages of gradients (m) and squared gradients (v)
2. Applies bias correction to account for initialization
3. Uses adaptive learning rates based on gradient magnitudes
</pre></div>
</div>
</div>
</div>
</section>
<section id="portfolio-impact">
<h2>Portfolio Impact<a class="headerlink" href="#portfolio-impact" title="Link to this heading">#</a></h2>
<p>This systematic analysis demonstrates:</p>
<ul class="simple">
<li><p><strong>Deep understanding</strong> of optimization algorithms</p></li>
<li><p><strong>Experimental rigor</strong> in hyperparameter tuning</p></li>
<li><p><strong>Data-driven insights</strong> for practical applications</p></li>
<li><p><strong>Communication skills</strong> in explaining complex concepts</p></li>
</ul>
<p>This work showcases the ability to move beyond “default settings” to truly understand and optimize deep learning systems.</p>
</section>
<section id="conclusion-and-key-takeaways">
<h2>Conclusion and Key Takeaways<a class="headerlink" href="#conclusion-and-key-takeaways" title="Link to this heading">#</a></h2>
<p>This systematic exploration of Adam’s hyperparameters reveals both the robustness of its default settings and the opportunities for optimization through careful tuning.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Conclusion and Key Takeaways</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;=&quot;</span><span class="o">*</span><span class="mi">80</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;CONCLUSION AND KEY TAKEAWAYS&quot;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;=&quot;</span><span class="o">*</span><span class="mi">80</span><span class="p">)</span>

<span class="n">key_takeaways</span> <span class="o">=</span> <span class="p">[</span>
    <span class="s2">&quot;Adam&#39;s parameters DO need tuning for optimal performance&quot;</span><span class="p">,</span>
    <span class="s2">&quot;Learning rate has the most significant impact on final accuracy&quot;</span><span class="p">,</span>
    <span class="s2">&quot;Beta1 controls the trade-off between speed and stability&quot;</span><span class="p">,</span> 
    <span class="s2">&quot;Beta2 affects how quickly the optimizer adapts to gradient variance&quot;</span><span class="p">,</span>
    <span class="s2">&quot;Epsilon is not just for numerical stability - it affects convergence&quot;</span><span class="p">,</span>
    <span class="s2">&quot;Different problems benefit from different Adam configurations&quot;</span><span class="p">,</span>
    <span class="s2">&quot;Understanding Adam&#39;s mechanics helps debug training issues&quot;</span><span class="p">,</span>
    <span class="s2">&quot;The default settings are good starting points but rarely optimal&quot;</span>
<span class="p">]</span>

<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;</span><span class="se">\n</span><span class="s2">Key Insights from Our Experiments:&quot;</span><span class="p">)</span>
<span class="k">for</span> <span class="n">i</span><span class="p">,</span> <span class="n">takeaway</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">key_takeaways</span><span class="p">,</span> <span class="mi">1</span><span class="p">):</span>
    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;</span><span class="si">{</span><span class="n">i</span><span class="si">}</span><span class="s2">. </span><span class="si">{</span><span class="n">takeaway</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>

<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Educational Value:&quot;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;This deep dive moves beyond &#39;just use Adam&#39; to truly understanding:&quot;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;• The mathematical foundation of adaptive optimization&quot;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;• How each parameter influences training dynamics&quot;</span><span class="p">)</span>  
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;• Practical tuning strategies for different scenarios&quot;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;• The importance of empirical validation over theoretical defaults&quot;</span><span class="p">)</span>

<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Portfolio Impact:&quot;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;This analysis demonstrates:&quot;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;• Deep understanding of optimization algorithms&quot;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;• Systematic experimental methodology&quot;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;• Data-driven decision making in ML&quot;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;• Ability to extract practical insights from theoretical concepts&quot;</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>================================================================================
CONCLUSION AND KEY TAKEAWAYS
================================================================================

Key Insights from Our Experiments:
1. Adam&#39;s parameters DO need tuning for optimal performance
2. Learning rate has the most significant impact on final accuracy
3. Beta1 controls the trade-off between speed and stability
4. Beta2 affects how quickly the optimizer adapts to gradient variance
5. Epsilon is not just for numerical stability - it affects convergence
6. Different problems benefit from different Adam configurations
7. Understanding Adam&#39;s mechanics helps debug training issues
8. The default settings are good starting points but rarely optimal
Educational Value:
This deep dive moves beyond &#39;just use Adam&#39; to truly understanding:
• The mathematical foundation of adaptive optimization
• How each parameter influences training dynamics
• Practical tuning strategies for different scenarios
• The importance of empirical validation over theoretical defaults
Portfolio Impact:
This analysis demonstrates:
• Deep understanding of optimization algorithms
• Systematic experimental methodology
• Data-driven decision making in ML
• Ability to extract practical insights from theoretical concepts
</pre></div>
</div>
</div>
</div>
</section>
<section id="references">
<h2>References<a class="headerlink" href="#references" title="Link to this heading">#</a></h2>
<ol class="arabic simple">
<li><p>Kingma, D. P., &amp; Ba, J. (2014). Adam: A Method for Stochastic Optimization. <em>arXiv:1412.6980</em></p></li>
<li><p><a class="reference external" href="https://arxiv.org/abs/1412.6980">Original Adam Paper</a></p></li>
<li><p>TensorFlow Optimization Documentation</p></li>
</ol>
</section>
</section>

    <script type="text/x-thebe-config">
    {
        requestKernel: true,
        binderOptions: {
            repo: "binder-examples/jupyter-stacks-datascience",
            ref: "master",
        },
        codeMirrorConfig: {
            theme: "abcdef",
            mode: "python"
        },
        kernelOptions: {
            name: "python3",
            path: "./Blog_Post"
        },
        predefinedOutput: true
    }
    </script>
    <script>kernelName = 'python3'</script>

                </article>
              

              
              
              
              
                <footer class="prev-next-footer d-print-none">
                  
<div class="prev-next-area">
    <a class="left-prev"
       href="../group-activities/temporal.html"
       title="previous page">
      <i class="fa-solid fa-angle-left"></i>
      <div class="prev-next-info">
        <p class="prev-next-subtitle">previous</p>
        <p class="prev-next-title">Applying Temporal Fusion Transformers for Air Quality Forecasting in Metro Manila</p>
      </div>
    </a>
</div>
                </footer>
              
            </div>
            
            
              
                <div class="bd-sidebar-secondary bd-toc"><div class="sidebar-secondary-items sidebar-secondary__inner">


  <div class="sidebar-secondary-item">
  <div class="page-toc tocsection onthispage">
    <i class="fa-solid fa-list"></i> Contents
  </div>
  <nav class="bd-toc-nav page-toc">
    <ul class="visible nav section-nav flex-column">
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#introduction">Introduction</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#why-this-matters">Why This Matters</a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#theoretical-foundation">Theoretical Foundation</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#what-is-adam">What is Adam?</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#the-adam-update-equations">The Adam Update Equations</a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#experimental-setup">Experimental Setup</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#methodology">Methodology</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#parameters-tested">Parameters Tested</a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#experiment-1-learning-rate-sensitivity">Experiment 1: Learning Rate Sensitivity</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#what-we-re-testing">What We’re Testing</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#hypothesis">Hypothesis</a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#results-analysis">Results Analysis</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#key-questions">Key Questions:</a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#key-insights-and-findings">Key Insights and Findings</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#practical-recommendations-for-practitioners">Practical Recommendations for Practitioners</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#understanding-adam-through-code">Understanding Adam Through Code</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#portfolio-impact">Portfolio Impact</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#conclusion-and-key-takeaways">Conclusion and Key Takeaways</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#references">References</a></li>
</ul>
  </nav></div>

</div></div>
              
            
          </div>
          <footer class="bd-footer-content">
            
<div class="bd-footer-content__inner container">
  
  <div class="footer-item">
    
<p class="component-author">
By Dane Casey C Casino
</p>

  </div>
  
  <div class="footer-item">
    

  <p class="copyright">
    
      © Copyright 2023.
      <br/>
    
  </p>

  </div>
  
  <div class="footer-item">
    
  </div>
  
  <div class="footer-item">
    
  </div>
  
</div>
          </footer>
        

      </main>
    </div>
  </div>
  
  <!-- Scripts loaded after <body> so the DOM is not blocked -->
  <script src="../_static/scripts/bootstrap.js?digest=dfe6caa3a7d634c4db9b"></script>
<script src="../_static/scripts/pydata-sphinx-theme.js?digest=dfe6caa3a7d634c4db9b"></script>

  <footer class="bd-footer">
  </footer>
  </body>
</html>