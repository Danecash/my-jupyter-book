{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ac05ac7d",
   "metadata": {},
   "source": [
    "**Laboratory Activty**\n",
    "\n",
    "`Instruction:` Convert the following CNN architecture diagram into a PyTorch CNN Architecture.\n",
    "\n",
    "![image](quick_draw.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c12156bf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device: cpu\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 9.91M/9.91M [00:10<00:00, 935kB/s] \n",
      "100%|██████████| 28.9k/28.9k [00:00<00:00, 94.1kB/s]\n",
      "100%|██████████| 1.65M/1.65M [00:04<00:00, 360kB/s]\n",
      "100%|██████████| 4.54k/4.54k [00:00<00:00, 475kB/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Flatten features into FC1: 6272\n",
      "Total params: 7,018,766\n",
      "\n",
      "=== Epoch 1/3 ===\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train:   0%|          | 0/469 [00:00<?, ?it/s]d:\\Anaconda\\envs\\myenv\\lib\\site-packages\\torch\\utils\\data\\dataloader.py:666: UserWarning: 'pin_memory' argument is set as true but no accelerator is found, then device pinned memory won't be used.\n",
      "  warnings.warn(warn_msg)\n",
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.1597 | Train Acc: 94.89%\n",
      "Val   Loss: 0.0531 | Val   Acc: 98.41%\n",
      "Saved best model (val acc 98.41%) -> diagram_cnn.pth\n",
      "\n",
      "=== Epoch 2/3 ===\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                 \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.0447 | Train Acc: 98.70%\n",
      "Val   Loss: 0.0385 | Val   Acc: 98.67%\n",
      "Saved best model (val acc 98.67%) -> diagram_cnn.pth\n",
      "\n",
      "=== Epoch 3/3 ===\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.0330 | Train Acc: 98.97%\n",
      "Val   Loss: 0.0313 | Val   Acc: 99.00%\n",
      "Saved best model (val acc 99.00%) -> diagram_cnn.pth\n",
      "\n",
      "Training complete. Best val accuracy: 99.00%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import random\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader\n",
    "import torchvision\n",
    "from torchvision import transforms\n",
    "from tqdm import tqdm\n",
    "\n",
    "# -------------------------\n",
    "# Config / hyperparameters\n",
    "# -------------------------\n",
    "RANDOM_SEED = 42\n",
    "BATCH_SIZE = 128\n",
    "LR = 1e-3\n",
    "NUM_EPOCHS = 3        # increase for real training\n",
    "IN_CHANNELS = 1       # diagram used (1, 28, 28)\n",
    "NUM_CLASSES = 10      # change to your problem's class count\n",
    "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "MODEL_SAVE_PATH = \"diagram_cnn.pth\"\n",
    "\n",
    "# -------------------------\n",
    "# Reproducibility\n",
    "# -------------------------\n",
    "torch.manual_seed(RANDOM_SEED)\n",
    "random.seed(RANDOM_SEED)\n",
    "if torch.cuda.is_available():\n",
    "    torch.cuda.manual_seed_all(RANDOM_SEED)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "\n",
    "# -------------------------\n",
    "# Model (matches diagram)\n",
    "# -------------------------\n",
    "class DiagramCNN(nn.Module):\n",
    "    def __init__(self, in_channels=1, num_classes=10):\n",
    "        super().__init__()\n",
    "        # Convolutional block\n",
    "        self.conv1 = nn.Conv2d(in_channels, 32, kernel_size=3, stride=1, padding=1)\n",
    "        self.pool1 = nn.MaxPool2d(kernel_size=2, stride=2, padding=1)\n",
    "\n",
    "        self.conv2 = nn.Conv2d(32, 64, kernel_size=3, stride=1, padding=1)\n",
    "        self.conv3 = nn.Conv2d(64, 128, kernel_size=3, stride=1, padding=1)\n",
    "        self.conv4 = nn.Conv2d(128, 128, kernel_size=3, stride=1, padding=1)\n",
    "        self.pool2 = nn.MaxPool2d(kernel_size=2, stride=2, padding=0)\n",
    "\n",
    "        self.dropout = nn.Dropout(p=0.2)\n",
    "\n",
    "        # compute flattened size for FC input with a dummy forward\n",
    "        with torch.no_grad():\n",
    "            d = torch.zeros(1, in_channels, 28, 28)\n",
    "            d = F.relu(self.conv1(d))\n",
    "            d = self.pool1(d)\n",
    "            d = F.relu(self.conv2(d))\n",
    "            d = F.relu(self.conv3(d))\n",
    "            d = F.relu(self.conv4(d))\n",
    "            d = self.pool2(d)\n",
    "            flat_features = d.numel()\n",
    "\n",
    "        # Fully connected layers (diagram: 1000, 500, final)\n",
    "        self.fc1 = nn.Linear(flat_features, 1000)\n",
    "        self.fc2 = nn.Linear(1000, 500)\n",
    "        self.fc3 = nn.Linear(500, num_classes)\n",
    "\n",
    "        self._flat_features = flat_features\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.conv1(x))\n",
    "        x = self.pool1(x)\n",
    "\n",
    "        x = F.relu(self.conv2(x))\n",
    "        x = F.relu(self.conv3(x))\n",
    "        x = F.relu(self.conv4(x))\n",
    "\n",
    "        x = self.pool2(x)\n",
    "        x = self.dropout(x)\n",
    "\n",
    "        x = torch.flatten(x, 1)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = self.fc3(x)\n",
    "        return x\n",
    "\n",
    "# -------------------------\n",
    "# Data (MNIST)\n",
    "# -------------------------\n",
    "def get_dataloaders(batch_size=BATCH_SIZE):\n",
    "    transform = transforms.Compose([\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize((0.1307,), (0.3081,))  # MNIST mean/std\n",
    "    ])\n",
    "\n",
    "    train_set = torchvision.datasets.MNIST(root=\"./data\", train=True, download=True, transform=transform)\n",
    "    test_set = torchvision.datasets.MNIST(root=\"./data\", train=False, download=True, transform=transform)\n",
    "\n",
    "    train_loader = DataLoader(train_set, batch_size=batch_size, shuffle=True, num_workers=2, pin_memory=True)\n",
    "    test_loader = DataLoader(test_set, batch_size=batch_size, shuffle=False, num_workers=2, pin_memory=True)\n",
    "\n",
    "    return train_loader, test_loader\n",
    "\n",
    "# -------------------------\n",
    "# Training / evaluation utilities\n",
    "# -------------------------\n",
    "def train_one_epoch(model, dataloader, criterion, optimizer, device):\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    pbar = tqdm(dataloader, desc=\"Train\", leave=False)\n",
    "    for imgs, labels in pbar:\n",
    "        imgs, labels = imgs.to(device), labels.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(imgs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        running_loss += loss.item() * imgs.size(0)\n",
    "        preds = outputs.argmax(dim=1)\n",
    "        correct += (preds == labels).sum().item()\n",
    "        total += labels.size(0)\n",
    "        pbar.set_postfix(loss=loss.item(), acc=100.0 * correct / total)\n",
    "\n",
    "    epoch_loss = running_loss / total\n",
    "    epoch_acc = 100.0 * correct / total\n",
    "    return epoch_loss, epoch_acc\n",
    "\n",
    "def evaluate(model, dataloader, criterion, device):\n",
    "    model.eval()\n",
    "    running_loss = 0.0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    with torch.no_grad():\n",
    "        pbar = tqdm(dataloader, desc=\"Eval \", leave=False)\n",
    "        for imgs, labels in pbar:\n",
    "            imgs, labels = imgs.to(device), labels.to(device)\n",
    "            outputs = model(imgs)\n",
    "            loss = criterion(outputs, labels)\n",
    "            running_loss += loss.item() * imgs.size(0)\n",
    "            preds = outputs.argmax(dim=1)\n",
    "            correct += (preds == labels).sum().item()\n",
    "            total += labels.size(0)\n",
    "    epoch_loss = running_loss / total\n",
    "    epoch_acc = 100.0 * correct / total\n",
    "    return epoch_loss, epoch_acc\n",
    "\n",
    "# -------------------------\n",
    "# Main training loop\n",
    "# -------------------------\n",
    "def main():\n",
    "    print(\"Device:\", DEVICE)\n",
    "    train_loader, test_loader = get_dataloaders()\n",
    "\n",
    "    model = DiagramCNN(in_channels=IN_CHANNELS, num_classes=NUM_CLASSES).to(DEVICE)\n",
    "    print(\"Flatten features into FC1:\", model._flat_features)\n",
    "    total_params = sum(p.numel() for p in model.parameters())\n",
    "    print(f\"Total params: {total_params:,}\")\n",
    "\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=LR)\n",
    "\n",
    "    best_acc = 0.0\n",
    "    for epoch in range(1, NUM_EPOCHS + 1):\n",
    "        print(f\"\\n=== Epoch {epoch}/{NUM_EPOCHS} ===\")\n",
    "        train_loss, train_acc = train_one_epoch(model, train_loader, criterion, optimizer, DEVICE)\n",
    "        val_loss, val_acc = evaluate(model, test_loader, criterion, DEVICE)\n",
    "\n",
    "        print(f\"Train Loss: {train_loss:.4f} | Train Acc: {train_acc:.2f}%\")\n",
    "        print(f\"Val   Loss: {val_loss:.4f} | Val   Acc: {val_acc:.2f}%\")\n",
    "\n",
    "        # save best\n",
    "        if val_acc > best_acc:\n",
    "            best_acc = val_acc\n",
    "            torch.save(model.state_dict(), MODEL_SAVE_PATH)\n",
    "            print(f\"Saved best model (val acc {best_acc:.2f}%) -> {MODEL_SAVE_PATH}\")\n",
    "\n",
    "    print(\"\\nTraining complete. Best val accuracy: {:.2f}%\".format(best_acc))\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a809a4d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (myenv)",
   "language": "python",
   "name": "myenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
