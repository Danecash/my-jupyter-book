
<!DOCTYPE html>


<html lang="en" data-content_root="../../" >

  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" /><meta name="viewport" content="width=device-width, initial-scale=1" />

    <title>Lecture 2 - Understanding Deep Learning &#8212; My JupyterBook</title>
  
  
  
  <script data-cfasync="false">
    document.documentElement.dataset.mode = localStorage.getItem("mode") || "";
    document.documentElement.dataset.theme = localStorage.getItem("theme") || "";
  </script>
  
  <!-- Loaded before other Sphinx assets -->
  <link href="../../_static/styles/theme.css?digest=dfe6caa3a7d634c4db9b" rel="stylesheet" />
<link href="../../_static/styles/bootstrap.css?digest=dfe6caa3a7d634c4db9b" rel="stylesheet" />
<link href="../../_static/styles/pydata-sphinx-theme.css?digest=dfe6caa3a7d634c4db9b" rel="stylesheet" />

  
  <link href="../../_static/vendor/fontawesome/6.5.2/css/all.min.css?digest=dfe6caa3a7d634c4db9b" rel="stylesheet" />
  <link rel="preload" as="font" type="font/woff2" crossorigin href="../../_static/vendor/fontawesome/6.5.2/webfonts/fa-solid-900.woff2" />
<link rel="preload" as="font" type="font/woff2" crossorigin href="../../_static/vendor/fontawesome/6.5.2/webfonts/fa-brands-400.woff2" />
<link rel="preload" as="font" type="font/woff2" crossorigin href="../../_static/vendor/fontawesome/6.5.2/webfonts/fa-regular-400.woff2" />

    <link rel="stylesheet" type="text/css" href="../../_static/pygments.css?v=03e43079" />
    <link rel="stylesheet" type="text/css" href="../../_static/styles/sphinx-book-theme.css?v=eba8b062" />
    <link rel="stylesheet" type="text/css" href="../../_static/togglebutton.css?v=13237357" />
    <link rel="stylesheet" type="text/css" href="../../_static/copybutton.css?v=76b2166b" />
    <link rel="stylesheet" type="text/css" href="../../_static/mystnb.8ecb98da25f57f5357bf6f572d296f466b2cfe2517ffebfabe82451661e28f02.css?v=6644e6bb" />
    <link rel="stylesheet" type="text/css" href="../../_static/sphinx-thebe.css?v=4fa983c6" />
    <link rel="stylesheet" type="text/css" href="../../_static/sphinx-design.min.css?v=95c83b7e" />
  
  <!-- Pre-loaded scripts that we'll load fully later -->
  <link rel="preload" as="script" href="../../_static/scripts/bootstrap.js?digest=dfe6caa3a7d634c4db9b" />
<link rel="preload" as="script" href="../../_static/scripts/pydata-sphinx-theme.js?digest=dfe6caa3a7d634c4db9b" />
  <script src="../../_static/vendor/fontawesome/6.5.2/js/all.min.js?digest=dfe6caa3a7d634c4db9b"></script>

    <script src="../../_static/documentation_options.js?v=9eb32ce0"></script>
    <script src="../../_static/doctools.js?v=9a2dae69"></script>
    <script src="../../_static/sphinx_highlight.js?v=dc90522c"></script>
    <script src="../../_static/clipboard.min.js?v=a7894cd8"></script>
    <script src="../../_static/copybutton.js?v=f281be69"></script>
    <script src="../../_static/scripts/sphinx-book-theme.js?v=887ef09a"></script>
    <script>let toggleHintShow = 'Click to show';</script>
    <script>let toggleHintHide = 'Click to hide';</script>
    <script>let toggleOpenOnPrint = 'true';</script>
    <script src="../../_static/togglebutton.js?v=4a39c7ea"></script>
    <script>var togglebuttonSelector = '.toggle, .admonition.dropdown';</script>
    <script src="../../_static/design-tabs.js?v=f930bc37"></script>
    <script>const THEBE_JS_URL = "https://unpkg.com/thebe@0.8.2/lib/index.js"; const thebe_selector = ".thebe,.cell"; const thebe_selector_input = "pre"; const thebe_selector_output = ".output, .cell_output"</script>
    <script async="async" src="../../_static/sphinx-thebe.js?v=c100c467"></script>
    <script>var togglebuttonSelector = '.toggle, .admonition.dropdown';</script>
    <script>const THEBE_JS_URL = "https://unpkg.com/thebe@0.8.2/lib/index.js"; const thebe_selector = ".thebe,.cell"; const thebe_selector_input = "pre"; const thebe_selector_output = ".output, .cell_output"</script>
    <script>window.MathJax = {"options": {"processHtmlClass": "tex2jax_process|mathjax_process|math|output_area"}}</script>
    <script defer="defer" src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
    <script>DOCUMENTATION_OPTIONS.pagename = 'lectures/lesson2/lesson2';</script>
    <link rel="canonical" href="/my-jupyter-book/lectures/lesson2/lesson2.html" />
    <link rel="index" title="Index" href="../../genindex.html" />
    <link rel="search" title="Search" href="../../search.html" />
    <link rel="next" title="Lecture 3 - PyTorch Tensor Objects Attributes and Methods" href="../lesson3/lesson3.html" />
    <link rel="prev" title="Lecture 1 - Foundational Concept of Deep Learning" href="../lesson1/lesson1.html" />
  <meta name="viewport" content="width=device-width, initial-scale=1"/>
  <meta name="docsearch:language" content="en"/>
  </head>
  
  
  <body data-bs-spy="scroll" data-bs-target=".bd-toc-nav" data-offset="180" data-bs-root-margin="0px 0px -60%" data-default-mode="">

  
  
  <div id="pst-skip-link" class="skip-link d-print-none"><a href="#main-content">Skip to main content</a></div>
  
  <div id="pst-scroll-pixel-helper"></div>
  
  <button type="button" class="btn rounded-pill" id="pst-back-to-top">
    <i class="fa-solid fa-arrow-up"></i>Back to top</button>

  
  <input type="checkbox"
          class="sidebar-toggle"
          id="pst-primary-sidebar-checkbox"/>
  <label class="overlay overlay-primary" for="pst-primary-sidebar-checkbox"></label>
  
  <input type="checkbox"
          class="sidebar-toggle"
          id="pst-secondary-sidebar-checkbox"/>
  <label class="overlay overlay-secondary" for="pst-secondary-sidebar-checkbox"></label>
  
  <div class="search-button__wrapper">
    <div class="search-button__overlay"></div>
    <div class="search-button__search-container">
<form class="bd-search d-flex align-items-center"
      action="../../search.html"
      method="get">
  <i class="fa-solid fa-magnifying-glass"></i>
  <input type="search"
         class="form-control"
         name="q"
         id="search-input"
         placeholder="Search this book..."
         aria-label="Search this book..."
         autocomplete="off"
         autocorrect="off"
         autocapitalize="off"
         spellcheck="false"/>
  <span class="search-button__kbd-shortcut"><kbd class="kbd-shortcut__modifier">Ctrl</kbd>+<kbd>K</kbd></span>
</form></div>
  </div>

  <div class="pst-async-banner-revealer d-none">
  <aside id="bd-header-version-warning" class="d-none d-print-none" aria-label="Version warning"></aside>
</div>

  
    <header class="bd-header navbar navbar-expand-lg bd-navbar d-print-none">
    </header>
  

  <div class="bd-container">
    <div class="bd-container__inner bd-page-width">
      
      
      
      <div class="bd-sidebar-primary bd-sidebar">
        

  
  <div class="sidebar-header-items sidebar-primary__section">
    
    
    
    
  </div>
  
    <div class="sidebar-primary-items__start sidebar-primary__section">
        <div class="sidebar-primary-item">

  
    
  

<a class="navbar-brand logo" href="../../intro.html">
  
  
  
  
  
    
    
      
    
    
    <img src="../../_static/logo.png" class="logo__image only-light" alt="My JupyterBook - Home"/>
    <script>document.write(`<img src="../../_static/logo.png" class="logo__image only-dark" alt="My JupyterBook - Home"/>`);</script>
  
  
</a></div>
        <div class="sidebar-primary-item">

 <script>
 document.write(`
   <button class="btn search-button-field search-button__button" title="Search" aria-label="Search" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <i class="fa-solid fa-magnifying-glass"></i>
    <span class="search-button__default-text">Search</span>
    <span class="search-button__kbd-shortcut"><kbd class="kbd-shortcut__modifier">Ctrl</kbd>+<kbd class="kbd-shortcut__modifier">K</kbd></span>
   </button>
 `);
 </script></div>
        <div class="sidebar-primary-item"><nav class="bd-links bd-docs-nav" aria-label="Main">
    <div class="bd-toc-item navbar-nav active">
        
        <ul class="nav bd-sidenav bd-sidenav__home-link">
            <li class="toctree-l1">
                <a class="reference internal" href="../../intro.html">
                    Welcome to your Jupyter Book
                </a>
            </li>
        </ul>
        <p aria-level="2" class="caption" role="heading"><span class="caption-text">Lectures</span></p>
<ul class="current nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="../lesson1/lesson1.html">Lecture 1 - Foundational Concept of Deep Learning</a></li>
<li class="toctree-l1 current active"><a class="current reference internal" href="#">Lecture 2 - Understanding Deep Learning</a></li>
<li class="toctree-l1"><a class="reference internal" href="../lesson3/lesson3.html">Lecture 3 - PyTorch Tensor Objects Attributes and Methods</a></li>
<li class="toctree-l1"><a class="reference internal" href="../lesson4/lesson4.html">Lecture 4 - Main Types of Deep Learning Neural Networks</a></li>
<li class="toctree-l1"><a class="reference internal" href="../lesson5/lesson5.html">Lecture 5 - Applications of Deep Learning</a></li>
<li class="toctree-l1"><a class="reference internal" href="../lesson6/lesson6.html">Lecture 6 - Training CNN Model using MNIST Dataset</a></li>
</ul>
<p aria-level="2" class="caption" role="heading"><span class="caption-text">Exercises</span></p>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="../../exercises/exercise-1-python-basics.html">Reaction Paper: “Machine Learning: Living in the Age of AI | A WIRED Film”</a></li>
</ul>
<p aria-level="2" class="caption" role="heading"><span class="caption-text">Labs</span></p>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="../../labs/Laboratory%20Activty%201.html">Laboratory Activty 1</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../labs/Laboratory%20Activty%202.html">Laboratory Activty 2</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../labs/Laboratory%20Activity%203.html">Laboratory Activity 3</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../labs/Laboratory%20Activity%204.html">Laboratory Activity 4</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../labs/lab-5-pytorch-intro.html">Laboratory Task 5</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../labs/Laboratory_Activty.html">Laboratory Task 6</a></li>
</ul>
<p aria-level="2" class="caption" role="heading"><span class="caption-text">Group Projects</span></p>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="../../group-activities/resources.html">Group Activities</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../group-activities/temporal.html">Applying Temporal Fusion Transformers for Air Quality Forecasting in Metro Manila</a></li>
</ul>

    </div>
</nav></div>
    </div>
  
  
  <div class="sidebar-primary-items__end sidebar-primary__section">
  </div>
  
  <div id="rtd-footer-container"></div>


      </div>
      
      <main id="main-content" class="bd-main" role="main">
        
        

<div class="sbt-scroll-pixel-helper"></div>

          <div class="bd-content">
            <div class="bd-article-container">
              
              <div class="bd-header-article d-print-none">
<div class="header-article-items header-article__inner">
  
    <div class="header-article-items__start">
      
        <div class="header-article-item"><button class="sidebar-toggle primary-toggle btn btn-sm" title="Toggle primary sidebar" data-bs-placement="bottom" data-bs-toggle="tooltip">
  <span class="fa-solid fa-bars"></span>
</button></div>
      
    </div>
  
  
    <div class="header-article-items__end">
      
        <div class="header-article-item">

<div class="article-header-buttons">





<div class="dropdown dropdown-source-buttons">
  <button class="btn dropdown-toggle" type="button" data-bs-toggle="dropdown" aria-expanded="false" aria-label="Source repositories">
    <i class="fab fa-github"></i>
  </button>
  <ul class="dropdown-menu">
      
      
      
      <li><a href="https://github.com/Danecash/my-jupyter-book" target="_blank"
   class="btn btn-sm btn-source-repository-button dropdown-item"
   title="Source repository"
   data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fab fa-github"></i>
  </span>
<span class="btn__text-container">Repository</span>
</a>
</li>
      
      
      
      
      <li><a href="https://github.com/Danecash/my-jupyter-book/issues/new?title=Issue%20on%20page%20%2Flectures/lesson2/lesson2.html&body=Your%20issue%20content%20here." target="_blank"
   class="btn btn-sm btn-source-issues-button dropdown-item"
   title="Open an issue"
   data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-lightbulb"></i>
  </span>
<span class="btn__text-container">Open issue</span>
</a>
</li>
      
  </ul>
</div>






<div class="dropdown dropdown-download-buttons">
  <button class="btn dropdown-toggle" type="button" data-bs-toggle="dropdown" aria-expanded="false" aria-label="Download this page">
    <i class="fas fa-download"></i>
  </button>
  <ul class="dropdown-menu">
      
      
      
      <li><a href="../../_sources/lectures/lesson2/lesson2.ipynb" target="_blank"
   class="btn btn-sm btn-download-source-button dropdown-item"
   title="Download source file"
   data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-file"></i>
  </span>
<span class="btn__text-container">.ipynb</span>
</a>
</li>
      
      
      
      
      <li>
<button onclick="window.print()"
  class="btn btn-sm btn-download-pdf-button dropdown-item"
  title="Print to PDF"
  data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-file-pdf"></i>
  </span>
<span class="btn__text-container">.pdf</span>
</button>
</li>
      
  </ul>
</div>




<button onclick="toggleFullScreen()"
  class="btn btn-sm btn-fullscreen-button"
  title="Fullscreen mode"
  data-bs-placement="bottom" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-expand"></i>
  </span>

</button>



<script>
document.write(`
  <button class="btn btn-sm nav-link pst-navbar-icon theme-switch-button" title="light/dark" aria-label="light/dark" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <i class="theme-switch fa-solid fa-sun fa-lg" data-mode="light"></i>
    <i class="theme-switch fa-solid fa-moon fa-lg" data-mode="dark"></i>
    <i class="theme-switch fa-solid fa-circle-half-stroke fa-lg" data-mode="auto"></i>
  </button>
`);
</script>


<script>
document.write(`
  <button class="btn btn-sm pst-navbar-icon search-button search-button__button" title="Search" aria-label="Search" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <i class="fa-solid fa-magnifying-glass fa-lg"></i>
  </button>
`);
</script>
<button class="sidebar-toggle secondary-toggle btn btn-sm" title="Toggle secondary sidebar" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <span class="fa-solid fa-list"></span>
</button>
</div></div>
      
    </div>
  
</div>
</div>
              
              

<div id="jb-print-docs-body" class="onlyprint">
    <h1>Lecture 2 - Understanding Deep Learning</h1>
    <!-- Table of contents -->
    <div id="print-main-content">
        <div id="jb-print-toc">
            
            <div>
                <h2> Contents </h2>
            </div>
            <nav aria-label="Page">
                <ul class="visible nav section-nav flex-column">
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#artificial-neural-network">Artificial Neural Network</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#feedforward-neural-network">Feedforward Neural Network</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#backward-propagation-of-errors">Backward Propagation of Errors</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#introduction-to-pytorch">Introduction to PyTorch</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#setting-up-the-virtual-environment">Setting up the Virtual Environment</a><ul class="nav section-nav flex-column">
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#with-pip">With PIP</a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#with-conda">With CONDA</a></li>
</ul>
</li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#pytorch-installation">PyTorch Installation</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#pytorch-components">PyTorch Components</a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#sample-implementation">Sample Implementation</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#specifiying-input-and-target"><strong>1. Specifiying input and target</strong></a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#dataset-and-dataloader"><strong>2. Dataset and DataLoader</strong></a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#define-some-layer-nn-linear"><strong>3. Define some Layer - nn.Linear</strong></a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#define-loss-function"><strong>4. Define Loss Function</strong></a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#define-the-optimizer"><strong>5. Define the Optimizer</strong></a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#training-putting-everything-together"><strong>6. Training - Putting Everything Together</strong></a></li>
</ul>
</li>
</ul>
            </nav>
        </div>
    </div>
</div>

              
                
<div id="searchbox"></div>
                <article class="bd-article">
                  
  <section class="tex2jax_ignore mathjax_ignore" id="lecture-2-understanding-deep-learning">
<h1>Lecture 2 - Understanding Deep Learning<a class="headerlink" href="#lecture-2-understanding-deep-learning" title="Link to this heading">#</a></h1>
<p>Having explored the historical background and inspiration behind deep learning, we can now delve into understanding the underlying mechanisms of this seemingly sci-fi technology. This journey will uncover how deep learning works, including the foundational concepts, methodologies, and real-world applications that make it a transformative force in modern technology.</p>
<section id="artificial-neural-network">
<h2>Artificial Neural Network<a class="headerlink" href="#artificial-neural-network" title="Link to this heading">#</a></h2>
<p>Artificial Neural Networks (ANNs) consist of artificial neurons, known as units, organized into layers that form the entire network. These layers can range from having a few dozen units to millions, depending on the complexity required to learn hidden patterns in the data. Typically, an ANN includes an input layer, one or more hidden layers, and an output layer. The input layer receives external data for analysis, which is then processed through the hidden layers that transform the input into valuable information for the output layer. The output layer then generates a response based on the processed data.</p>
<p><img alt="ANN Structure" src="../../_images/example1.png" /></p>
<p>In most neural networks, units in different layers are interconnected, with each connection having a weight that determines the influence of one unit on another. As data flows through these connections, the neural network progressively learns from the data, ultimately producing an output from the output layer. Artificial neural networks are trained using a dataset. To teach an ANN to recognize a cat, it is presented with thousands of different cat images. The network learns to identify cats by analyzing these images. Once trained, the ANN is tested by classifying new images and determining whether they are cat images or not. The output is compared to a human-provided label. If the ANN misclassifies an image, backpropagation is used to refine the network’s weights based on the error rate. This process iterates until the ANN can accurately recognize cat images with minimal errors.</p>
</section>
<section id="feedforward-neural-network">
<h2>Feedforward Neural Network<a class="headerlink" href="#feedforward-neural-network" title="Link to this heading">#</a></h2>
<p>The feedforward neural network is one of the most basic artificial neural networks. In this ANN, the data or the input provided travels in a single direction. It enters into the ANN through the input layer and exits through the output layer while hidden layers may or may not exist. So the feedforward neural network has a front-propagated wave only and usually does not have backpropagation.</p>
<p>Assume that the neurons have a sigmoid activation function, perform a forward pass on the network. Assume that the actual output of <span class="math notranslate nohighlight">\(y\)</span> is 1 and learning rate <span class="math notranslate nohighlight">\(\\alpha\)</span> is 0.9.</p>
<p>To calculate <span class="math notranslate nohighlight">\(H_1\)</span>, we need to calculate first the weighted sum of the input values added by the bias <span class="math notranslate nohighlight">\(\\theta\)</span>.</p>
<div class="math notranslate nohighlight">
\[\begin{split}
Z = \\sum_j (w_{i,j} \\cdot x_i) + \\theta_i
\end{split}\]</div>
<div class="math notranslate nohighlight">
\[\begin{split}
Z_1 = (w_{11} \\cdot x_1) + (w_{13} \\cdot x_2) + (w_{15} \\cdot x_3) + \\theta_1
\end{split}\]</div>
<div class="math notranslate nohighlight">
\[\begin{split}
Z_2 = (w_{12} \\cdot x_1) + (w_{14} \\cdot x_2) + (w_{16} \\cdot x_3) + \\theta_2
\end{split}\]</div>
<p>After computing the weighted sum, we introduce non-linearity to the output result by applying a nonlinear function. For this example, let’s use sigmoid function.</p>
<div class="math notranslate nohighlight">
\[\begin{split}
\\sigma = \\frac{1}{1 + e^{-Z_i}}
\end{split}\]</div>
<div class="math notranslate nohighlight">
\[\begin{split}
H_1 = \\sigma(Z_1)
\end{split}\]</div>
<div class="math notranslate nohighlight">
\[\begin{split}
H_2 = \\sigma(Z_2)
\end{split}\]</div>
<p>Now that we have computed the hidden layer’s value, we can now proceed to computing the weighted sum for the output layer using the same procedure as how we compute the <span class="math notranslate nohighlight">\(Z_n\)</span> and <span class="math notranslate nohighlight">\(H_n\)</span>.</p>
<div class="math notranslate nohighlight">
\[\begin{split}
Z_3 = (w_{21} \\cdot H_1) + (w_{22} \\cdot H_2) + \\theta_3
\end{split}\]</div>
<div class="math notranslate nohighlight">
\[\begin{split}
\\hat{y} = \\sigma(Z_3)
\end{split}\]</div>
<p>This is how the calculations in a feedforward neural network are traversed from input to output.</p>
</section>
<section id="backward-propagation-of-errors">
<h2>Backward Propagation of Errors<a class="headerlink" href="#backward-propagation-of-errors" title="Link to this heading">#</a></h2>
<p>Backward propagation a.k.a backprop or backward pass is a fundamental algorithm used for training artificial neural networks. It involves a two-step process: a forward pass and a backward pass. During the forward pass, input data is fed through the network, and the output is generated. The error, or the difference between the predicted output and the actual target, is then calculated. In the backward pass, this error is propagated back through the network, layer by layer, to update the weights and biases. This is done by computing the gradient of the loss function with respect to each weight using the chain rule of calculus. By iteratively adjusting the weights in the direction that reduces the error, backpropagation helps the network learn and improve its performance over time. This process continues until the network’s predictions are sufficiently accurate or another stopping criterion is met.</p>
<p>The initial value for <span class="math notranslate nohighlight">\(\\hat{y}\)</span> is not the optimal value since the parameters used were just randomly selected. Therefore, after the forward propagation, a backward propagation algorithm is employed to update the parameters (<span class="math notranslate nohighlight">\(w\)</span> and <span class="math notranslate nohighlight">\(\\theta\)</span>).</p>
<p>The error at the output layer is calculated as the difference between the predicted output (<span class="math notranslate nohighlight">\(\\hat{y}\)</span>) and the actual output (<span class="math notranslate nohighlight">\(y\)</span>):</p>
<div class="math notranslate nohighlight">
\[\begin{split}
\\delta = \\hat{y} - y
\end{split}\]</div>
<p><strong>Compute Hidden Layer Error (<span class="math notranslate nohighlight">\(\\delta_h\)</span>)</strong>
$<span class="math notranslate nohighlight">\(
\\delta_h = (\\delta_o W^T_o) \\cdot \\sigma'(Z_h)
\)</span>$</p>
<p>Where:</p>
<ul class="simple">
<li><p><span class="math notranslate nohighlight">\(\\sigma'(Z_h)\)</span> is the derivative of the sigmoid activation function applied to the hidden layer activations <span class="math notranslate nohighlight">\(Z_h\)</span>:
$<span class="math notranslate nohighlight">\(
\\sigma'(Z_h) = A_h \\cdot (1 - A_h)
\)</span>$</p></li>
<li><p><span class="math notranslate nohighlight">\(W^T_o\)</span> is the transpose of the output weights matrix <span class="math notranslate nohighlight">\(W_o\)</span>.</p></li>
</ul>
<p><strong>Calculate Gradients</strong></p>
<p>Once we have the errors (<span class="math notranslate nohighlight">\(\\delta_o\)</span> and <span class="math notranslate nohighlight">\(\\delta_h\)</span>), we compute the gradients of the error with respect to the weights (<span class="math notranslate nohighlight">\(W_o\)</span> and <span class="math notranslate nohighlight">\(W_h\)</span>).</p>
<p><strong>Gradients for Output Layer Weights (<span class="math notranslate nohighlight">\(\\frac{\\partial E}{\\partial W_o}\)</span>)</strong>
$<span class="math notranslate nohighlight">\(
\\frac{\\partial E}{\\partial W_o} = A^T_h \\delta_o
\)</span>$</p>
<p><strong>Gradients for Hidden Layer Weights (<span class="math notranslate nohighlight">\(\\frac{\\partial E}{\\partial W_h}\)</span>)</strong>
$<span class="math notranslate nohighlight">\(
\\frac{\\partial E}{\\partial W_h} = X^T \\delta_h
\)</span>$</p>
<p>Finally, the weights are updated using the gradients and the learning rate (<span class="math notranslate nohighlight">\(\\alpha\)</span>).</p>
</section>
<section id="introduction-to-pytorch">
<h2>Introduction to PyTorch<a class="headerlink" href="#introduction-to-pytorch" title="Link to this heading">#</a></h2>
<p><img alt="PyTorch Logo" src="../../_images/Pytorch_logo.png" /></p>
<p>PyTorch is a powerful and widely-used open-source framework for deep learning, developed by Facebook’s AI Research lab. It is designed to provide flexibility and speed for both research and production environments. PyTorch’s primary strength lies in its dynamic computation graph, which allows for real-time changes and debugging, making it easier to experiment with new ideas. This is in contrast to static computation graphs used by other frameworks like TensorFlow. PyTorch supports a range of applications, from natural language processing to computer vision, through its extensive library of pre-built modules and tools. Additionally, its integration with Python makes it accessible to a large community of developers and researchers, fostering rapid development and collaboration. With a strong emphasis on simplicity and performance, PyTorch has become a go-to tool for many in the deep learning community.</p>
<section id="setting-up-the-virtual-environment">
<h3>Setting up the Virtual Environment<a class="headerlink" href="#setting-up-the-virtual-environment" title="Link to this heading">#</a></h3>
<p>A virtual environment is a self-contained directory that isolates a specific Python environment, allowing users to manage dependencies and packages for different projects independently. This ensures that each project can have its own unique set of libraries and versions without conflicts, avoiding issues that arise from global installations. Virtual environments are particularly useful for maintaining consistent development environments, making it easier to manage project-specific dependencies and ensuring that applications run smoothly across different setups. Tools like venv and virtualenv facilitate the creation and management of these environments. We can create a virtual environment using either pip or conda.</p>
<section id="with-pip">
<h4>With PIP<a class="headerlink" href="#with-pip" title="Link to this heading">#</a></h4>
<ol class="arabic simple">
<li><p>Make sure that you have installed python and have its directory path added in the machine’s environment variables.</p></li>
<li><p>Create a new folder, make sure that you know the directory of the new folder that you have created.</p></li>
<li><p>Open command prompt and change the directory to the new folder that you created.</p></li>
<li><p>Considering that you already have configured pip in the environment variables, you can now install libraries.</p></li>
<li><p>Run command <code class="docutils literal notranslate"><span class="pre">pip</span> <span class="pre">install</span> <span class="pre">virtualenv</span></code>.</p></li>
<li><p>You can create a virtual environment with a specific python version but only if the specific version is installed in your system.</p></li>
<li><p>Run command <code class="docutils literal notranslate"><span class="pre">virtualenv</span> <span class="pre">-p</span> <span class="pre">/path/to/pythonX.X</span> <span class="pre">/path/to/new/virtual/environment</span></code></p>
<ul class="simple">
<li><p>Replace <code class="docutils literal notranslate"><span class="pre">/path/to/pythonX.X</span></code> with the path to the desired Python executable (e.g., <code class="docutils literal notranslate"><span class="pre">/usr/bin/python3.8</span></code>)</p></li>
<li><p>Replace <code class="docutils literal notranslate"><span class="pre">/path/to/new/virtual/environment</span></code> with the path where you want to create the virtual environment.</p></li>
</ul>
</li>
<li><p>Activate the virtual environment, make sure that you are inside the directory where the environment’s folder is also under.</p></li>
<li><p>Run command <code class="docutils literal notranslate"><span class="pre">env_name/Scripts/activate</span></code></p>
<ul class="simple">
<li><p>Replace <code class="docutils literal notranslate"><span class="pre">env_name</span></code> with the name of the environment you created.</p></li>
</ul>
</li>
</ol>
</section>
<section id="with-conda">
<h4>With CONDA<a class="headerlink" href="#with-conda" title="Link to this heading">#</a></h4>
<ol class="arabic simple">
<li><p>Make sure that anaconda is installed in you system.</p></li>
<li><p>Open anaconda prompt and run command <code class="docutils literal notranslate"><span class="pre">conda</span> <span class="pre">create</span> <span class="pre">-n</span> <span class="pre">python=3.X</span></code></p></li>
<li><p>Activate the environment by running the command <code class="docutils literal notranslate"><span class="pre">conda</span> <span class="pre">activate</span> <span class="pre">env_name</span></code>.</p>
<ul class="simple">
<li><p>Replace <code class="docutils literal notranslate"><span class="pre">env_name</span></code> with the name of the environment you created.</p></li>
</ul>
</li>
</ol>
</section>
</section>
<section id="pytorch-installation">
<h3>PyTorch Installation<a class="headerlink" href="#pytorch-installation" title="Link to this heading">#</a></h3>
<ol class="arabic simple">
<li><p>Make sure that python is installed in your local device, the stable version of pytorch runs on python version 3.6 to 3.9. Make sure that your python version is in between this range. You can check the python version using command the command:</p></li>
</ol>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>python<span class="w"> </span>--version
</pre></div>
</div>
<ol class="arabic simple" start="2">
<li><p>Activate the virtual environment, for this demonstration, let’s just use the conda virtual enviroment.</p></li>
</ol>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>conda<span class="w"> </span>activate<span class="w"> </span>env_name
</pre></div>
</div>
<ol class="arabic simple" start="3">
<li><p>Go to <a class="reference external" href="https://pytorch.org/get-started/locally/">https://pytorch.org/get-started/locally/</a> and select appropriate machine configurations and copy the generated command.
If you have a CUDA enabled GPU, you can download and install CUDA toolkit version 11.8 or 12.1 first. Otherwise you may only select CPU.</p></li>
</ol>
<p><img alt="image" src="../../_images/torch.png" /></p>
<ol class="arabic" start="4">
<li><p>Paste the command in the anaconda prompt where you activated the virtual enviroment and wait patiently.
Just click</p>
<p>Y</p>
<p>when prompted with a question to proceed installation.</p>
</li>
</ol>
<p><img alt="image" src="../../_images/torch2.png" /></p>
</section>
<section id="pytorch-components">
<h3>PyTorch Components<a class="headerlink" href="#pytorch-components" title="Link to this heading">#</a></h3>
<p>Let’s have linear regression as a case study to study the different components of PyTorch. These are the following components we will be covering:</p>
<ol class="arabic">
<li><p>Specifying input and target</p></li>
<li><p>Dataset and DataLoader</p></li>
<li><p>nn.Linear</p>
<p>(Dense)</p>
</li>
<li><p>Define loss function</p></li>
<li><p>Define optimizer function</p></li>
<li><p>Train the model</p></li>
</ol>
<p>Consider this data:</p>
<p><img alt="image" src="../../_images/japan.png" /></p>
<p>In a linear regression model, each target variable is estimated to be a weighted sum of the input variables, offset by some constant, known as a bias:</p>
<div class="math notranslate nohighlight">
\[
\text{yield}_{\text{apple}} = w_{11} \cdot \text{temp} + w_{12} \cdot \text{rainfall} + w_{13} \cdot \text{humidity} + b_1
\]</div>
<div class="math notranslate nohighlight">
\[
\text{yield}_{\text{orange}} = w_{21} \cdot \text{temp} + w_{22} \cdot \text{rainfall} + w_{23} \cdot \text{humidity} + b_2
\]</div>
<p>Visually, it means that the yield of apples is a linear or planar function of temperature, rainfall and humidity:</p>
<p><img alt="image" src="../../_images/japan2.png" /></p>
<p>The learning part of linear regression is to figure out a set of weights <strong>w11, w12,… w23, b1 &amp; b2</strong> using gradient descent.</p>
</section>
</section>
<section id="sample-implementation">
<h2>Sample Implementation<a class="headerlink" href="#sample-implementation" title="Link to this heading">#</a></h2>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span><span class="w"> </span><span class="nn">torch</span>
<span class="kn">import</span><span class="w"> </span><span class="nn">numpy</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">np</span>
<span class="kn">import</span><span class="w"> </span><span class="nn">sys</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">torch</span><span class="o">.</span><span class="n">__version__</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>&#39;2.8.0+cpu&#39;
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1">#We can check whether we have gpu</span>
<span class="n">device</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">device</span><span class="p">(</span><span class="s2">&quot;cuda:0&quot;</span> <span class="k">if</span> <span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">cuda</span><span class="o">.</span><span class="n">is_available</span><span class="p">())</span> <span class="k">else</span> <span class="s2">&quot;cpu&quot;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Device: &quot;</span><span class="p">,</span> <span class="n">device</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Device:  cpu
</pre></div>
</div>
</div>
</div>
<section id="specifiying-input-and-target">
<h3><strong>1. Specifiying input and target</strong><a class="headerlink" href="#specifiying-input-and-target" title="Link to this heading">#</a></h3>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Input (temp, rainfall, humidity)</span>
<span class="n">x_train</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([</span>
    <span class="p">[</span><span class="mi">73</span><span class="p">,</span> <span class="mi">67</span><span class="p">,</span> <span class="mi">43</span><span class="p">],</span> <span class="p">[</span><span class="mi">91</span><span class="p">,</span> <span class="mi">88</span><span class="p">,</span> <span class="mi">64</span><span class="p">],</span> <span class="p">[</span><span class="mi">87</span><span class="p">,</span> <span class="mi">134</span><span class="p">,</span> <span class="mi">58</span><span class="p">],</span> 
    <span class="p">[</span><span class="mi">102</span><span class="p">,</span> <span class="mi">43</span><span class="p">,</span> <span class="mi">37</span><span class="p">],</span> <span class="p">[</span><span class="mi">69</span><span class="p">,</span> <span class="mi">96</span><span class="p">,</span> <span class="mi">70</span><span class="p">],</span> <span class="p">[</span><span class="mi">73</span><span class="p">,</span> <span class="mi">67</span><span class="p">,</span> <span class="mi">43</span><span class="p">],</span> 
    <span class="p">[</span><span class="mi">91</span><span class="p">,</span> <span class="mi">88</span><span class="p">,</span> <span class="mi">64</span><span class="p">],</span> <span class="p">[</span><span class="mi">87</span><span class="p">,</span> <span class="mi">134</span><span class="p">,</span> <span class="mi">58</span><span class="p">],</span> <span class="p">[</span><span class="mi">102</span><span class="p">,</span> <span class="mi">43</span><span class="p">,</span> <span class="mi">37</span><span class="p">],</span> 
    <span class="p">[</span><span class="mi">69</span><span class="p">,</span> <span class="mi">96</span><span class="p">,</span> <span class="mi">70</span><span class="p">],</span> <span class="p">[</span><span class="mi">73</span><span class="p">,</span> <span class="mi">67</span><span class="p">,</span> <span class="mi">43</span><span class="p">],</span> <span class="p">[</span><span class="mi">91</span><span class="p">,</span> <span class="mi">88</span><span class="p">,</span> <span class="mi">64</span><span class="p">],</span> 
    <span class="p">[</span><span class="mi">87</span><span class="p">,</span> <span class="mi">134</span><span class="p">,</span> <span class="mi">58</span><span class="p">],</span> <span class="p">[</span><span class="mi">102</span><span class="p">,</span> <span class="mi">43</span><span class="p">,</span> <span class="mi">37</span><span class="p">],</span> <span class="p">[</span><span class="mi">69</span><span class="p">,</span> <span class="mi">96</span><span class="p">,</span> <span class="mi">70</span><span class="p">]],</span> 
                   <span class="n">dtype</span><span class="o">=</span><span class="s1">&#39;float32&#39;</span><span class="p">)</span>

<span class="c1"># Targets (apples, oranges)</span>
<span class="n">y_train</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([</span>
    <span class="p">[</span><span class="mi">56</span><span class="p">,</span> <span class="mi">70</span><span class="p">],</span> <span class="p">[</span><span class="mi">81</span><span class="p">,</span> <span class="mi">101</span><span class="p">],</span> <span class="p">[</span><span class="mi">119</span><span class="p">,</span> <span class="mi">133</span><span class="p">],</span> 
    <span class="p">[</span><span class="mi">22</span><span class="p">,</span> <span class="mi">37</span><span class="p">],</span> <span class="p">[</span><span class="mi">103</span><span class="p">,</span> <span class="mi">119</span><span class="p">],</span> <span class="p">[</span><span class="mi">56</span><span class="p">,</span> <span class="mi">70</span><span class="p">],</span> 
    <span class="p">[</span><span class="mi">81</span><span class="p">,</span> <span class="mi">101</span><span class="p">],</span> <span class="p">[</span><span class="mi">119</span><span class="p">,</span> <span class="mi">133</span><span class="p">],</span> <span class="p">[</span><span class="mi">22</span><span class="p">,</span> <span class="mi">37</span><span class="p">],</span> 
    <span class="p">[</span><span class="mi">103</span><span class="p">,</span> <span class="mi">119</span><span class="p">],</span> <span class="p">[</span><span class="mi">56</span><span class="p">,</span> <span class="mi">70</span><span class="p">],</span> <span class="p">[</span><span class="mi">81</span><span class="p">,</span> <span class="mi">101</span><span class="p">],</span> 
    <span class="p">[</span><span class="mi">119</span><span class="p">,</span> <span class="mi">133</span><span class="p">],</span> <span class="p">[</span><span class="mi">22</span><span class="p">,</span> <span class="mi">37</span><span class="p">],</span> <span class="p">[</span><span class="mi">103</span><span class="p">,</span> <span class="mi">119</span><span class="p">]],</span> 
                   <span class="n">dtype</span><span class="o">=</span><span class="s1">&#39;float32&#39;</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">inputs</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">from_numpy</span><span class="p">(</span><span class="n">x_train</span><span class="p">)</span>
<span class="n">targets</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">from_numpy</span><span class="p">(</span><span class="n">y_train</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">inputs</span><span class="o">.</span><span class="n">size</span><span class="p">())</span>
<span class="nb">print</span><span class="p">(</span><span class="n">targets</span><span class="o">.</span><span class="n">size</span><span class="p">())</span>
<span class="n">torch</span><span class="o">.</span><span class="n">Size</span><span class="p">([</span><span class="mi">15</span><span class="p">,</span> <span class="mi">3</span><span class="p">])</span>
<span class="n">torch</span><span class="o">.</span><span class="n">Size</span><span class="p">([</span><span class="mi">15</span><span class="p">,</span> <span class="mi">2</span><span class="p">])</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>torch.Size([15, 3])
torch.Size([15, 2])
</pre></div>
</div>
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>torch.Size([15, 2])
</pre></div>
</div>
</div>
</div>
</section>
<section id="dataset-and-dataloader">
<h3><strong>2. Dataset and DataLoader</strong><a class="headerlink" href="#dataset-and-dataloader" title="Link to this heading">#</a></h3>
<p>PyTorch provides two data primitives: <strong>torch.utils.data.DataLoader</strong> and <strong>torch.utils.data.Dataset</strong> that allow you to use pre-loaded datasets as well as your own data. Dataset stores the samples and their corresponding labels, and DataLoader wraps an iterable around the Dataset to enable easy access to the samples.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span><span class="w"> </span><span class="nn">torch.utils.data</span><span class="w"> </span><span class="kn">import</span> <span class="n">TensorDataset</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Define dataset</span>
<span class="n">train_ds</span> <span class="o">=</span> <span class="n">TensorDataset</span><span class="p">(</span><span class="n">inputs</span><span class="p">,</span> <span class="n">targets</span><span class="p">)</span>
<span class="n">train_ds</span><span class="p">[</span><span class="mi">0</span><span class="p">:</span><span class="mi">3</span><span class="p">]</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>(tensor([[ 73.,  67.,  43.],
         [ 91.,  88.,  64.],
         [ 87., 134.,  58.]]),
 tensor([[ 56.,  70.],
         [ 81., 101.],
         [119., 133.]]))
</pre></div>
</div>
</div>
</div>
<p>We’ll now create a <strong>DataLoader</strong>, which can split the data into batches of a predefined size while training. It also provides other utilities like shuffling and random sampling of the data.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span><span class="w"> </span><span class="nn">torch.utils.data</span><span class="w"> </span><span class="kn">import</span> <span class="n">DataLoader</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Define data loader</span>
<span class="n">batch_size</span> <span class="o">=</span> <span class="mi">3</span>
<span class="n">train_dl</span> <span class="o">=</span> <span class="n">DataLoader</span><span class="p">(</span><span class="n">train_ds</span><span class="p">,</span> <span class="n">batch_size</span><span class="p">,</span> <span class="n">shuffle</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<p>The <strong>DataLoader</strong> is typically used in a for-in loop. Let’s look at an example</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="k">for</span> <span class="n">xb</span><span class="p">,</span> <span class="n">yb</span> <span class="ow">in</span> <span class="n">train_dl</span><span class="p">:</span>
    <span class="nb">print</span><span class="p">(</span><span class="n">xb</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="n">yb</span><span class="p">)</span>
    <span class="k">break</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>tensor([[ 91.,  88.,  64.],
        [102.,  43.,  37.],
        [ 87., 134.,  58.]])
tensor([[ 81., 101.],
        [ 22.,  37.],
        [119., 133.]])
</pre></div>
</div>
</div>
</div>
<p>In each iteration, the data loader returns one batch of data, with the given batch size. If shuffle is set to True, it shuffles the training data before creating batches. Shuffling helps randomize the input to the optimization algorithm, which can lead to faster reduction in the loss.</p>
</section>
<section id="define-some-layer-nn-linear">
<h3><strong>3. Define some Layer - nn.Linear</strong><a class="headerlink" href="#define-some-layer-nn-linear" title="Link to this heading">#</a></h3>
<p>Instead of initializing the weights &amp; biases manually, we can define the model using the <strong>nn.Linear</strong> class from PyTorch, which does it automatically.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span><span class="w"> </span><span class="nn">torch.nn</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">nn</span>

<span class="c1"># Define model</span>
<span class="n">model</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="mi">3</span><span class="p">,</span> <span class="mi">2</span><span class="p">)</span>  <span class="c1">#nn.Linear assume this shape (in_features, out_features)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">model</span><span class="o">.</span><span class="n">weight</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">model</span><span class="o">.</span><span class="n">weight</span><span class="o">.</span><span class="n">size</span><span class="p">())</span> <span class="c1"># (out_features, in_features)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">model</span><span class="o">.</span><span class="n">bias</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">model</span><span class="o">.</span><span class="n">bias</span><span class="o">.</span><span class="n">size</span><span class="p">())</span> <span class="c1">#(out_features)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Parameter containing:
tensor([[-0.0092,  0.1423,  0.5002],
        [ 0.1088,  0.0923,  0.3803]], requires_grad=True)
torch.Size([2, 3])
Parameter containing:
tensor([-0.3465,  0.5074], requires_grad=True)
torch.Size([2])
</pre></div>
</div>
</div>
</div>
<p>In fact, our model is simply a function that performs a matrix multiplication of the <strong>inputs</strong> and the weights <strong>w</strong> and adds the bias <strong>b</strong> (for each observation)</p>
<p><img alt="image" src="../../_images/dot.png" /></p>
<p>PyTorch models also have a helpful <strong>.parameters</strong> method, which returns a list containing all the weights and bias matrices present in the model. For our linear regression model, we have one weight matrix and one bias matrix.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Parameters</span>
<span class="nb">list</span><span class="p">(</span><span class="n">model</span><span class="o">.</span><span class="n">parameters</span><span class="p">())</span>  <span class="c1">#model.param returns a generator</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>[Parameter containing:
 tensor([[-0.0092,  0.1423,  0.5002],
         [ 0.1088,  0.0923,  0.3803]], requires_grad=True),
 Parameter containing:
 tensor([-0.3465,  0.5074], requires_grad=True)]
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1">#we can print the complexity by the number of parameters</span>
<span class="nb">print</span><span class="p">(</span><span class="nb">sum</span><span class="p">(</span><span class="n">p</span><span class="o">.</span><span class="n">numel</span><span class="p">()</span> <span class="k">for</span> <span class="n">p</span> <span class="ow">in</span> <span class="n">model</span><span class="o">.</span><span class="n">parameters</span><span class="p">()</span> <span class="k">if</span> <span class="n">p</span><span class="o">.</span><span class="n">requires_grad</span><span class="p">))</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>8
</pre></div>
</div>
</div>
</div>
<p>We can use the <strong>model(tensor)</strong> API to perform a forward-pass that generate predictions.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Generate predictions</span>
<span class="n">preds</span> <span class="o">=</span> <span class="n">model</span><span class="p">(</span><span class="n">inputs</span><span class="p">)</span>
<span class="n">preds</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>tensor([[30.0196, 30.9854],
        [43.3450, 42.8677],
        [46.9256, 44.3950],
        [23.3360, 29.6454],
        [47.6875, 43.4933],
        [30.0196, 30.9854],
        [43.3450, 42.8677],
        [46.9256, 44.3950],
        [23.3360, 29.6454],
        [47.6875, 43.4933],
        [30.0196, 30.9854],
        [43.3450, 42.8677],
        [46.9256, 44.3950],
        [23.3360, 29.6454],
        [47.6875, 43.4933]], grad_fn=&lt;AddmmBackward0&gt;)
</pre></div>
</div>
</div>
</div>
</section>
<section id="define-loss-function">
<h3><strong>4. Define Loss Function</strong><a class="headerlink" href="#define-loss-function" title="Link to this heading">#</a></h3>
<p>The <strong>nn</strong> module contains a lot of useful loss function like this:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">criterion_mse</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">MSELoss</span><span class="p">()</span>
<span class="n">criterion_softmax_cross_entropy_loss</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">CrossEntropyLoss</span><span class="p">()</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">mse</span> <span class="o">=</span> <span class="n">criterion_mse</span><span class="p">(</span><span class="n">preds</span><span class="p">,</span> <span class="n">targets</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">mse</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">mse</span><span class="o">.</span><span class="n">item</span><span class="p">())</span>  <span class="c1">##print out the loss number</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>tensor(2885.6558, grad_fn=&lt;MseLossBackward0&gt;)
2885.65576171875
</pre></div>
</div>
</div>
</div>
</section>
<section id="define-the-optimizer">
<h3><strong>5. Define the Optimizer</strong><a class="headerlink" href="#define-the-optimizer" title="Link to this heading">#</a></h3>
<p>We use <strong>optim.SGD</strong> to perform stochastic gradient descent where samples are selected in batches (often with random shuffling) instead of as a single group. Note that <strong>model.parameters()</strong> is passed as an argument to <strong>optim.SGD.</strong></p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Define optimizer</span>
<span class="c1">#momentum update the weight based on past gradients also, which will be useful for getting out of local max/min</span>
<span class="c1">#If our momentum parameter was $0.9$, we would get our current grad + the multiplication of the gradient </span>
<span class="c1">#from one time step ago by $0.9$, the one from two time steps ago by $0.9^2 = 0.81$, etc.</span>

<span class="n">opt</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">optim</span><span class="o">.</span><span class="n">SGD</span><span class="p">(</span><span class="n">model</span><span class="o">.</span><span class="n">parameters</span><span class="p">(),</span> <span class="n">lr</span><span class="o">=</span><span class="mf">0.0001</span><span class="p">,</span> <span class="n">momentum</span><span class="o">=</span><span class="mf">0.9</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
</section>
<section id="training-putting-everything-together">
<h3><strong>6. Training - Putting Everything Together</strong><a class="headerlink" href="#training-putting-everything-together" title="Link to this heading">#</a></h3>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Utility function to train the model</span>
<span class="k">def</span><span class="w"> </span><span class="nf">fit</span><span class="p">(</span><span class="n">num_epochs</span><span class="p">,</span> <span class="n">model</span><span class="p">,</span> <span class="n">loss_fn</span><span class="p">,</span> <span class="n">opt</span><span class="p">,</span> <span class="n">train_dl</span><span class="p">):</span>
    
    <span class="c1"># Repeat for given number of epochs</span>
    <span class="k">for</span> <span class="n">epoch</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">num_epochs</span><span class="p">):</span>
        
        <span class="c1"># Train with batches of data</span>
        <span class="k">for</span> <span class="n">xb</span><span class="p">,</span><span class="n">yb</span> <span class="ow">in</span> <span class="n">train_dl</span><span class="p">:</span>
            
            <span class="n">xb</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">)</span> <span class="c1">#move them to gpu if possible, if not, it will be cpu</span>
            <span class="n">yb</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">)</span>
                    
            <span class="c1"># 1. Predict</span>
            <span class="n">pred</span> <span class="o">=</span> <span class="n">model</span><span class="p">(</span><span class="n">xb</span><span class="p">)</span>
                      
            <span class="c1"># 2. Calculate loss</span>
            <span class="n">loss</span> <span class="o">=</span> <span class="n">loss_fn</span><span class="p">(</span><span class="n">pred</span><span class="p">,</span> <span class="n">yb</span><span class="p">)</span>
            
            <span class="c1"># 3. Calculate gradient</span>
            <span class="n">opt</span><span class="o">.</span><span class="n">zero_grad</span><span class="p">()</span>  <span class="c1">#if not, the gradients will accumulate</span>
            <span class="n">loss</span><span class="o">.</span><span class="n">backward</span><span class="p">()</span>
            
            <span class="c1"># Print out the gradients.</span>
            <span class="c1"># print (&#39;dL/dw: &#39;, model.weight.grad) </span>
            <span class="c1"># print (&#39;dL/db: &#39;, model.bias.grad)</span>
            
            <span class="c1"># 4. Update parameters using gradients</span>
            <span class="n">opt</span><span class="o">.</span><span class="n">step</span><span class="p">()</span>
            
        <span class="c1"># Print the progress</span>
        <span class="k">if</span> <span class="p">(</span><span class="n">epoch</span><span class="o">+</span><span class="mi">1</span><span class="p">)</span> <span class="o">%</span> <span class="mi">10</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span>
            <span class="n">sys</span><span class="o">.</span><span class="n">stdout</span><span class="o">.</span><span class="n">write</span><span class="p">(</span><span class="s2">&quot;</span><span class="se">\r</span><span class="s2">Epoch [</span><span class="si">{}</span><span class="s2">/</span><span class="si">{}</span><span class="s2">], Loss: </span><span class="si">{:.4f}</span><span class="s2">&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">epoch</span><span class="o">+</span><span class="mi">1</span><span class="p">,</span> <span class="n">num_epochs</span><span class="p">,</span> <span class="n">loss</span><span class="o">.</span><span class="n">item</span><span class="p">()))</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1">#train for 100 epochs</span>
<span class="n">fit</span><span class="p">(</span><span class="mi">100</span><span class="p">,</span> <span class="n">model</span><span class="p">,</span> <span class="n">criterion_mse</span><span class="p">,</span> <span class="n">opt</span><span class="p">,</span> <span class="n">train_dl</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Epoch [10/100], Loss: 39.4738
Epoch [20/100], Loss: 357.6736
Epoch [30/100], Loss: 385.5547
Epoch [40/100], Loss: 16042.1758
Epoch [50/100], Loss: 2540.5823
Epoch [60/100], Loss: 58.5337
Epoch [70/100], Loss: 12.2660
Epoch [80/100], Loss: 476.8752
Epoch [90/100], Loss: 6.5189
Epoch [100/100], Loss: 11.5956
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Generate predictions</span>
<span class="n">preds</span> <span class="o">=</span> <span class="n">model</span><span class="p">(</span><span class="n">inputs</span><span class="p">)</span>
<span class="n">loss</span> <span class="o">=</span> <span class="n">criterion_mse</span><span class="p">(</span><span class="n">preds</span><span class="p">,</span> <span class="n">targets</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">loss</span><span class="o">.</span><span class="n">item</span><span class="p">())</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>3.75567889213562
</pre></div>
</div>
</div>
</div>
</section>
</section>
</section>

    <script type="text/x-thebe-config">
    {
        requestKernel: true,
        binderOptions: {
            repo: "binder-examples/jupyter-stacks-datascience",
            ref: "master",
        },
        codeMirrorConfig: {
            theme: "abcdef",
            mode: "myenv"
        },
        kernelOptions: {
            name: "myenv",
            path: "./lectures\lesson2"
        },
        predefinedOutput: true
    }
    </script>
    <script>kernelName = 'myenv'</script>

                </article>
              

              
              
              
              
                <footer class="prev-next-footer d-print-none">
                  
<div class="prev-next-area">
    <a class="left-prev"
       href="../lesson1/lesson1.html"
       title="previous page">
      <i class="fa-solid fa-angle-left"></i>
      <div class="prev-next-info">
        <p class="prev-next-subtitle">previous</p>
        <p class="prev-next-title">Lecture 1 - Foundational Concept of Deep Learning</p>
      </div>
    </a>
    <a class="right-next"
       href="../lesson3/lesson3.html"
       title="next page">
      <div class="prev-next-info">
        <p class="prev-next-subtitle">next</p>
        <p class="prev-next-title">Lecture 3 - PyTorch Tensor Objects Attributes and Methods</p>
      </div>
      <i class="fa-solid fa-angle-right"></i>
    </a>
</div>
                </footer>
              
            </div>
            
            
              
                <div class="bd-sidebar-secondary bd-toc"><div class="sidebar-secondary-items sidebar-secondary__inner">


  <div class="sidebar-secondary-item">
  <div class="page-toc tocsection onthispage">
    <i class="fa-solid fa-list"></i> Contents
  </div>
  <nav class="bd-toc-nav page-toc">
    <ul class="visible nav section-nav flex-column">
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#artificial-neural-network">Artificial Neural Network</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#feedforward-neural-network">Feedforward Neural Network</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#backward-propagation-of-errors">Backward Propagation of Errors</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#introduction-to-pytorch">Introduction to PyTorch</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#setting-up-the-virtual-environment">Setting up the Virtual Environment</a><ul class="nav section-nav flex-column">
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#with-pip">With PIP</a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#with-conda">With CONDA</a></li>
</ul>
</li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#pytorch-installation">PyTorch Installation</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#pytorch-components">PyTorch Components</a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#sample-implementation">Sample Implementation</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#specifiying-input-and-target"><strong>1. Specifiying input and target</strong></a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#dataset-and-dataloader"><strong>2. Dataset and DataLoader</strong></a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#define-some-layer-nn-linear"><strong>3. Define some Layer - nn.Linear</strong></a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#define-loss-function"><strong>4. Define Loss Function</strong></a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#define-the-optimizer"><strong>5. Define the Optimizer</strong></a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#training-putting-everything-together"><strong>6. Training - Putting Everything Together</strong></a></li>
</ul>
</li>
</ul>
  </nav></div>

</div></div>
              
            
          </div>
          <footer class="bd-footer-content">
            
<div class="bd-footer-content__inner container">
  
  <div class="footer-item">
    
<p class="component-author">
By Dane Casey C Casino
</p>

  </div>
  
  <div class="footer-item">
    

  <p class="copyright">
    
      © Copyright 2023.
      <br/>
    
  </p>

  </div>
  
  <div class="footer-item">
    
  </div>
  
  <div class="footer-item">
    
  </div>
  
</div>
          </footer>
        

      </main>
    </div>
  </div>
  
  <!-- Scripts loaded after <body> so the DOM is not blocked -->
  <script src="../../_static/scripts/bootstrap.js?digest=dfe6caa3a7d634c4db9b"></script>
<script src="../../_static/scripts/pydata-sphinx-theme.js?digest=dfe6caa3a7d634c4db9b"></script>

  <footer class="bd-footer">
  </footer>
  </body>
</html>